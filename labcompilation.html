<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.247">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>labcompilation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="labcompilation_files/libs/clipboard/clipboard.min.js"></script>
<script src="labcompilation_files/libs/quarto-html/quarto.js"></script>
<script src="labcompilation_files/libs/quarto-html/popper.min.js"></script>
<script src="labcompilation_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="labcompilation_files/libs/quarto-html/anchor.min.js"></script>
<link href="labcompilation_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="labcompilation_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="labcompilation_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="labcompilation_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="labcompilation_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#sec-1eda" id="toc-sec-1eda" class="nav-link active" data-scroll-target="#sec-1eda">Exploratory Data Analysis</a>
  <ul class="collapse">
  <li><a href="#sec-loaddata" id="toc-sec-loaddata" class="nav-link" data-scroll-target="#sec-loaddata">Loading Data</a></li>
  <li><a href="#sec-1datastruct" id="toc-sec-1datastruct" class="nav-link" data-scroll-target="#sec-1datastruct">Data Structure</a></li>
  <li><a href="#sec-1summarystat" id="toc-sec-1summarystat" class="nav-link" data-scroll-target="#sec-1summarystat">Summary Statistics</a></li>
  <li><a href="#sec-1datarestruct" id="toc-sec-1datarestruct" class="nav-link" data-scroll-target="#sec-1datarestruct">Data Restructuring</a></li>
  <li><a href="#sec-1edagraphs" id="toc-sec-1edagraphs" class="nav-link" data-scroll-target="#sec-1edagraphs">Graphs</a>
  <ul class="collapse">
  <li><a href="#sec-1edascatter" id="toc-sec-1edascatter" class="nav-link" data-scroll-target="#sec-1edascatter">Scatterplot</a></li>
  <li><a href="#sec-edabarplot" id="toc-sec-edabarplot" class="nav-link" data-scroll-target="#sec-edabarplot">Barplot</a></li>
  <li><a href="#sec-edahist" id="toc-sec-edahist" class="nav-link" data-scroll-target="#sec-edahist">Histogram</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#sec-2linearregression" id="toc-sec-2linearregression" class="nav-link" data-scroll-target="#sec-2linearregression">Linear Regression</a>
  <ul class="collapse">
  <li><a href="#sec-2loaddata" id="toc-sec-2loaddata" class="nav-link" data-scroll-target="#sec-2loaddata">Load Data</a></li>
  <li><a href="#sec-2buildmodel" id="toc-sec-2buildmodel" class="nav-link" data-scroll-target="#sec-2buildmodel">Build Model</a>
  <ul class="collapse">
  <li><a href="#sec-2fullmodel" id="toc-sec-2fullmodel" class="nav-link" data-scroll-target="#sec-2fullmodel">Full Model</a></li>
  <li><a href="#sec-2interactioneffect" id="toc-sec-2interactioneffect" class="nav-link" data-scroll-target="#sec-2interactioneffect">Model with interaction effect</a></li>
  </ul></li>
  <li><a href="#sec-2resampling" id="toc-sec-2resampling" class="nav-link" data-scroll-target="#sec-2resampling">Resampling Methods</a>
  <ul class="collapse">
  <li><a href="#sec-2holdout" id="toc-sec-2holdout" class="nav-link" data-scroll-target="#sec-2holdout">Hold-out</a></li>
  <li><a href="#cross-validation-cv" id="toc-cross-validation-cv" class="nav-link" data-scroll-target="#cross-validation-cv">Cross-Validation (CV)</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#sec-3class1" id="toc-sec-3class1" class="nav-link" data-scroll-target="#sec-3class1">Classification: Logistic Regression &amp; KNN</a>
  <ul class="collapse">
  <li><a href="#sec-3logistic" id="toc-sec-3logistic" class="nav-link" data-scroll-target="#sec-3logistic">Logistic Regression</a>
  <ul class="collapse">
  <li><a href="#hold-out-logistic-regression-model" id="toc-hold-out-logistic-regression-model" class="nav-link" data-scroll-target="#hold-out-logistic-regression-model">80/20 Hold-out Logistic Regression Model</a></li>
  <li><a href="#cross-validation-logistic-regression-model" id="toc-cross-validation-logistic-regression-model" class="nav-link" data-scroll-target="#cross-validation-logistic-regression-model">Cross-Validation Logistic Regression Model</a></li>
  <li><a href="#prediction-accuracy-of-cv-logistic-regression" id="toc-prediction-accuracy-of-cv-logistic-regression" class="nav-link" data-scroll-target="#prediction-accuracy-of-cv-logistic-regression">Prediction Accuracy of CV Logistic Regression</a></li>
  </ul></li>
  <li><a href="#knn" id="toc-knn" class="nav-link" data-scroll-target="#knn">KNN</a>
  <ul class="collapse">
  <li><a href="#data-scaling" id="toc-data-scaling" class="nav-link" data-scroll-target="#data-scaling">Data Scaling</a></li>
  <li><a href="#accuracy-of-knn-model" id="toc-accuracy-of-knn-model" class="nav-link" data-scroll-target="#accuracy-of-knn-model">Accuracy of KNN Model</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#sec-4class2" id="toc-sec-4class2" class="nav-link" data-scroll-target="#sec-4class2">Classification: CART, Bagging &amp; Random Forest</a>
  <ul class="collapse">
  <li><a href="#load-data" id="toc-load-data" class="nav-link" data-scroll-target="#load-data">Load Data</a></li>
  <li><a href="#hold-out-classification-tree" id="toc-hold-out-classification-tree" class="nav-link" data-scroll-target="#hold-out-classification-tree">80/20 Hold-out Classification Tree</a>
  <ul class="collapse">
  <li><a href="#performance-by-confusion-matrix" id="toc-performance-by-confusion-matrix" class="nav-link" data-scroll-target="#performance-by-confusion-matrix">Performance by Confusion Matrix</a></li>
  </ul></li>
  <li><a href="#regression-tree" id="toc-regression-tree" class="nav-link" data-scroll-target="#regression-tree">Regression Tree</a>
  <ul class="collapse">
  <li><a href="#load-data-1" id="toc-load-data-1" class="nav-link" data-scroll-target="#load-data-1">Load data</a></li>
  <li><a href="#regression-tree-model" id="toc-regression-tree-model" class="nav-link" data-scroll-target="#regression-tree-model">Regression Tree Model</a></li>
  <li><a href="#best-sub-tree-model" id="toc-best-sub-tree-model" class="nav-link" data-scroll-target="#best-sub-tree-model">Best Sub-Tree Model</a></li>
  <li><a href="#tree-model-performance" id="toc-tree-model-performance" class="nav-link" data-scroll-target="#tree-model-performance">Tree Model Performance</a></li>
  </ul></li>
  <li><a href="#random-forests-full-model" id="toc-random-forests-full-model" class="nav-link" data-scroll-target="#random-forests-full-model">Random Forests (FULL) Model</a>
  <ul class="collapse">
  <li><a href="#random-forest-full-model-performance" id="toc-random-forest-full-model-performance" class="nav-link" data-scroll-target="#random-forest-full-model-performance">Random Forest (FULL) Model Performance</a></li>
  <li><a href="#random-forest-model" id="toc-random-forest-model" class="nav-link" data-scroll-target="#random-forest-model">Random Forest Model</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#clustering" id="toc-clustering" class="nav-link" data-scroll-target="#clustering">Clustering</a>
  <ul class="collapse">
  <li><a href="#load-data-2" id="toc-load-data-2" class="nav-link" data-scroll-target="#load-data-2">Load Data</a>
  <ul class="collapse">
  <li><a href="#euclidean-distance-method" id="toc-euclidean-distance-method" class="nav-link" data-scroll-target="#euclidean-distance-method">Euclidean Distance Method</a></li>
  <li><a href="#hierarchical-clustering-model-comparison-on-selected-variables" id="toc-hierarchical-clustering-model-comparison-on-selected-variables" class="nav-link" data-scroll-target="#hierarchical-clustering-model-comparison-on-selected-variables">Hierarchical Clustering Model Comparison on Selected Variables</a></li>
  <li><a href="#plot-the-best-method-average-linkage" id="toc-plot-the-best-method-average-linkage" class="nav-link" data-scroll-target="#plot-the-best-method-average-linkage">Plot the best method, Average Linkage</a></li>
  </ul></li>
  <li><a href="#k-means-clustering" id="toc-k-means-clustering" class="nav-link" data-scroll-target="#k-means-clustering">K-Means Clustering</a></li>
  </ul></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">



<section id="sec-1eda" class="level1">
<h1>Exploratory Data Analysis</h1>
<section id="sec-loaddata" class="level2">
<h2 class="anchored" data-anchor-id="sec-loaddata">Loading Data</h2>
<p>Before the lab, please download and save data <code>AutoLab1.csv</code> from Blackboard-Data.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># use file.choose() if you want a window to open for you to locate your file</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Auto=read.csv(file.choose(),header=T, stringsAsFactors=TRUE)</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># if you know the path to your file you can directly include it and omit file.choose()</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>Auto<span class="ot">=</span><span class="fu">read.csv</span>(<span class="at">file=</span><span class="st">"../raw_data/autolab1.csv"</span>,</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>              <span class="at">header=</span>T, </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>              <span class="at">stringsAsFactors=</span><span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>You can use function <code>read.table()</code> or <code>read.csv()</code> to import data into R, depending on the file type. You can use <code>help(read.csv)</code> or <code>?read.csv</code> to find more about how to use this function. Since the file type is .csv, we use <code>read.csv()</code>in this case. Use the following command to load <code>AutoLab1.csv</code> into R and store it as an object called Auto.</p>
<p>The command, <code>file.choose()</code> locates the file from your local drive, the option <code>header=T</code> (or <code>header=TRUE</code>) means that the first line of the file contains the variable names, the option <code>stringsAsFactors=TRUE</code> (or <code>stringsAsFactors=T</code>) means that converting characters to factors</p>
</section>
<section id="sec-1datastruct" class="level2">
<h2 class="anchored" data-anchor-id="sec-1datastruct">Data Structure</h2>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Auto)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(Auto)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(Auto)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>You can use <code>head()</code> to look at the first 6 rows. Function <code>dim()</code> can output the number of rows followed by the number of columns and function <code>str()</code> can return the data structure.</p>
</section>
<section id="sec-1summarystat" class="level2">
<h2 class="anchored" data-anchor-id="sec-1summarystat">Summary Statistics</h2>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(Auto)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We can use function <code>summary()</code> to output the summary statistics of data.</p>
</section>
<section id="sec-1datarestruct" class="level2">
<h2 class="anchored" data-anchor-id="sec-1datarestruct">Data Restructuring</h2>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>Auto[,<span class="dv">2</span>]<span class="ot">=</span><span class="fu">as.factor</span>(Auto[,<span class="dv">2</span>])</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(Auto[,<span class="dv">2</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The variable cylinders (i.e.&nbsp;the second column) is stored as a quantitative variable. As it only has a small number of possible values, we can convert it to a qualitative variable. Function as.factor() converts a quantitative variable into a qualitative variable. Check the summary statistics of cylinders to see if it is the same as the output in <a href="#sec-1summarystat">Section&nbsp;1.3</a>.</p>
</section>
<section id="sec-1edagraphs" class="level2">
<h2 class="anchored" data-anchor-id="sec-1edagraphs">Graphs</h2>
<section id="sec-1edascatter" class="level3">
<h3 class="anchored" data-anchor-id="sec-1edascatter">Scatterplot</h3>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span>Auto<span class="sc">$</span>horsepower, <span class="at">y=</span>Auto<span class="sc">$</span>mpg)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We can use function plot() to produce plots. However, simply typing the variable names does not work, because R does not know where to find those variables. You can either use the <code>$</code>sign or</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(Auto)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(Auto)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span>horsepower , </span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">y=</span>mpg, <span class="at">col =</span><span class="st">"red"</span>, </span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">"Horsepower"</span>,</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span><span class="st">"MPG "</span>,</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">30</span>,<span class="dv">250</span>), </span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">50</span>), </span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>     <span class="at">main=</span><span class="st">"Horsepower vs. MPG"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Use function <code>attach()</code> to tell R to make the variables available by name. Function <code>names()</code> lists all variable names. Then you can use the variable name directly.</p>
<p>Here the option <code>col ="red"</code> tells R that color data points red. The options <code>xlab="Horsepower",ylab ="MPG"</code>, and <code>main="Horsepower vs. MPG"</code> tell R the x axis title, the y axis title and the main title respectively.</p>
<p>The options <code>xlim</code> and <code>ylim</code> tell R the range of x axis and y axis. There are many other optional parameters in function <code>plot()</code>, which we do not include in this case. You can use <code>help(plot)</code> or <code>?plot</code> to explore more about them.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span>acceleration ,</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">y=</span>mpg, </span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span><span class="st">"red"</span>, </span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">"Acceleration"</span>,</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span><span class="st">"MPG "</span>, </span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>     <span class="at">main=</span><span class="st">"Acceleration vs. MPG"</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span>weight , </span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>     <span class="at">y=</span>mpg, </span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span><span class="st">"red"</span>, </span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">"Weight"</span>, </span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span><span class="st">"MPG "</span>, </span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>     <span class="at">main=</span><span class="st">"Weight vs. MPG"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We can use function <code>par(mfrow=c(nrows,ncols))</code> to combine multiple plots into one graph. For example, <code>par(mfrow=c(3,1))</code> indicates that three figures will be arranged in 3 rows and 1 column. Now let’s generate another two figures and arrange them in one column.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(Auto)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(Auto[<span class="fu">c</span>(<span class="dv">3</span><span class="sc">:</span><span class="dv">5</span>)])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The <code>pairs()</code> function creates a scatterplot for every scatterplot pair of variables. We can also produce scatterplots matrix for just a subset of the variables.</p>
</section>
<section id="sec-edabarplot" class="level3">
<h3 class="anchored" data-anchor-id="sec-edabarplot">Barplot</h3>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span>cylinders, </span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">y=</span>mpg, </span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">col=</span><span class="st">"red"</span>, </span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">varwidth=</span><span class="cn">TRUE</span>, </span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">" Cylinders "</span>, </span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylab=</span><span class="st">"MPG "</span>, </span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">main=</span><span class="st">"Cylinders vs. MPG"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>If the variable plotted on the x-axis is categorical, then boxplots will automatically be produced.</p>
</section>
<section id="sec-edahist" class="level3">
<h3 class="anchored" data-anchor-id="sec-edahist">Histogram</h3>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(<span class="at">x=</span>mpg, </span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">breaks=</span><span class="dv">10</span>, </span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">col=</span><span class="st">"red"</span>, </span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">"MPG "</span>,</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">50</span>),</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">main=</span><span class="st">"Histogram of MPG"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We can use <code>hist()</code> function to plot a histogram. The option <code>“breaks=10”</code> sets the total number of bins.</p>
</section>
</section>
</section>
<section id="sec-2linearregression" class="level1">
<h1>Linear Regression</h1>
<section id="sec-2loaddata" class="level2">
<h2 class="anchored" data-anchor-id="sec-2loaddata">Load Data</h2>
<p>Before the lab, please download Data Lab2Data.csv from Blackboard→Data. Then load Data Lab2Data.csv to object Datlab2.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># delete global environment</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>())</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co"># load data</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>Datlab2 <span class="ot">=</span> <span class="fu">read.csv</span>(<span class="at">file=</span><span class="st">"../raw_data/Lab2Data.csv"</span>, </span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>                   <span class="at">header=</span>T, </span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>                   <span class="at">stringsAsFactors=</span><span class="cn">TRUE</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="co"># check column/variable names</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(Datlab2)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(Datlab2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>There are four input variables <span class="math inline">\((𝑥_1 ...𝑥_4)\)</span> and one response variable <span class="math inline">\(y\)</span> in this data. Variable <span class="math inline">\(x_4\)</span> is a categorical variable with two possible values. We should create a dummy variable that takes on two possible numerical values.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">contrasts</span>(x4)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The <code>contrasts()</code> function returns how R codes this dummy variable.</p>
</section>
<section id="sec-2buildmodel" class="level2">
<h2 class="anchored" data-anchor-id="sec-2buildmodel">Build Model</h2>
<section id="sec-2fullmodel" class="level3">
<h3 class="anchored" data-anchor-id="sec-2fullmodel">Full Model</h3>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>Model1<span class="ot">=</span><span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4,<span class="at">data=</span> Datlab2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We first fit the entire data with all input variables into a multiple linear regression model Model1. We can use the <code>lm()</code> function:</p>
<p><span id="eq-linearm1"><span class="math display">\[ y =\beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_4 + \epsilon \tag{1}\]</span></span></p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(Model1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We can use the function <code>summary()</code> to obtain the coefficients, their associated <code>p-values</code>, and the <span class="math inline">\(R^2\)</span>. We can find that only one variable looks insignificant in this model.</p>
</section>
<section id="sec-2interactioneffect" class="level3">
<h3 class="anchored" data-anchor-id="sec-2interactioneffect">Model with interaction effect</h3>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>Model2<span class="ot">=</span><span class="fu">lm</span>(y<span class="sc">~</span>x3<span class="sc">*</span>x4)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(Model2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We can also check if the model should include an interaction effect. For example, to test an interaction effect between <span class="math inline">\(x_3\)</span> and <span class="math inline">\(x_4\)</span>, we can include <code>lm(y~x3*x4)</code>. The syntax <code>x3*x4</code> in the function <code>lm()</code> simultaneously includes <span class="math inline">\(x_3\)</span>, <span class="math inline">\(x_4\)</span>, and <span class="math inline">\(x_3 \times x_4\)</span>𝑥4. That is, <code>lm(y~x3*x4)</code> fits the following model:</p>
<p><span id="eq-linearm2"><span class="math display">\[y = \beta_0 + \beta_1 x_3 + \beta_2 x_4 + \beta_3(x_3 \times x_4) + \epsilon \tag{2}\]</span></span> The result suggests that the interaction effect is significant.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span><span class="fu">predict</span>(Model2), <span class="at">y=</span><span class="fu">residuals</span>(Model2))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span><span class="fu">predict</span>(Model2), <span class="at">y=</span><span class="fu">rstudent</span>(Model2))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We can generate diagnostic plots for models. The function <code>rstudent()</code> returns the studentized residuals, which can be used to identity outliers. Given the diagnostics results, there is no outlier in <code>Model2</code>.</p>
</section>
</section>
<section id="sec-2resampling" class="level2">
<h2 class="anchored" data-anchor-id="sec-2resampling">Resampling Methods</h2>
<p>Now we try two candidate models <code>M1</code> and <code>M2</code>. We will use re-sampling methods to compare their performance.</p>
<p><span id="eq-M1"><span class="math display">\[M1: y =\beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_4 + \beta_5(x_3 \times x_4) +  \epsilon \tag{3}\]</span></span></p>
<p><span id="eq-M2"><span class="math display">\[M2: y = \beta_0 + \beta_1 x_3 + \beta_2 x_4 + \beta_3(x_3 \times x_4) + \epsilon \tag{4}\]</span></span></p>
<section id="sec-2holdout" class="level3">
<h3 class="anchored" data-anchor-id="sec-2holdout">Hold-out</h3>
<p>We use two types of re-sampling methods. First, we illustrate how to compare the models using hold-out. We use 80-20 hold-out in this case. We develop models using a training data set and assess the model performance using a test data set.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># reproduceable random sampling</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="co">#index for training data set</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>train<span class="ot">=</span><span class="fu">sample</span>(<span class="fu">nrow</span>(Datlab2),<span class="fu">nrow</span>(Datlab2)<span class="sc">*</span><span class="fl">0.8</span>) </span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="co">#training data set</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>Datlab2.train<span class="ot">=</span>Datlab2[train, ] </span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="co">#test data set</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>Datlab2.test<span class="ot">=</span>Datlab2[<span class="sc">-</span>train, ] </span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a><span class="co">#the response vector in the test set</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>y.test<span class="ot">=</span>y[<span class="sc">-</span>train] </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We first use the <code>sample()</code> function to randomly split the original data set into one training set and one test set.</p>
<p>The function <code>nrow()</code> counts the total number of rows in <code>Datlab2</code>. Sometimes we want to reproduce the exact same sampling results; we can use the <code>set.seed()</code> function. To use this function, you need to set a seed, which is an arbitrary integer, e.g.&nbsp;1.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># full model with train data</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>M1train<span class="ot">=</span><span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">*</span>x4, <span class="at">data=</span>Datlab2.train)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co"># interaction model with train data</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>M2train <span class="ot">=</span><span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x3<span class="sc">*</span>x4, <span class="at">data=</span>Datlab2.train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The first model of choice <code>M1</code> contains all four variables and one interaction term. The second model <code>M2</code> contains three input variables and one interaction term. We learn the two models only using the training data set.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># test performance of full model</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>y.predictM1<span class="ot">=</span><span class="fu">predict</span>(M1train,Datlab2.test)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co"># performance measure using MSE of full model</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>M1MSE<span class="ot">=</span><span class="fu">mean</span>((y.test<span class="sc">-</span>y.predictM1)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="co"># test performance of interaction model</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>y.predictM2<span class="ot">=</span><span class="fu">predict</span>(M2train,Datlab2.test)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="co"># performance measure using MSE of interaction model</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>M2MSE<span class="ot">=</span><span class="fu">mean</span>((y.test<span class="sc">-</span>y.predictM2)<span class="sc">^</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>To compare the model performance, we calculate the MSE of each model using the testing data set. The function <code>predict()</code> predicts the value of the response variable for each observation in test data. <code>y.predictM1</code> stores the predicted value of each observation in the test data set using model <code>M1</code>, and <code>y.predictM2</code> stores the predicted value of each observation in the test data set using model <code>M2</code>. The <code>mean()</code> function here is to calculate the average prediction deviation, i.e.&nbsp;MSE, in the entire test data.</p>
<section id="aic-bic-adjusted-r2" class="level4">
<h4 class="anchored" data-anchor-id="aic-bic-adjusted-r2">AIC, BIC, Adjusted <span class="math inline">\(R^2\)</span></h4>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># other performance measure of full model</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="fu">AIC</span>(M1train) <span class="co"># AIC</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="fu">BIC</span>(M1train) <span class="co"># BIC</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(M1train) <span class="co">#adj R2</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="co"># other performance measure of interaction model</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="fu">AIC</span>(M2train) <span class="co"># AIC</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a><span class="fu">BIC</span>(M2train) <span class="co"># BIC </span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(M2train) <span class="co"># adj. R2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>In addition to using MSE, the model can be assessed using functions <code>BIC()</code>, <code>AIC()</code> and adjusted R2 in <code>summary()</code>.</p>
</section>
</section>
<section id="cross-validation-cv" class="level3">
<h3 class="anchored" data-anchor-id="cross-validation-cv">Cross-Validation (CV)</h3>
<p>Now we illustrate how to compare the models using cross-validation. We use 5-fold cross validation along with MSE in this case.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># reproduceable random sampling</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>) </span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="co"># number of folds</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>k<span class="ot">=</span><span class="dv">5</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="co"># empty container to hold MSE of full model using CV</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>M1CVMSE<span class="ot">=</span><span class="fu">rep</span>(<span class="dv">0</span>,k)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="co"># emtpy container to hold MSE of interaction model using CV</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>M2CVMSE<span class="ot">=</span><span class="fu">rep</span>(<span class="dv">0</span>,k)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We first create a vector to store the accuracy results associated with each fold for each model. We set the initial values for this vector as zero.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># split data into k=5 folds </span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>folds<span class="ot">=</span><span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>k,<span class="fu">nrow</span>(Datlab2),<span class="at">replace=</span><span class="cn">TRUE</span>)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>folds</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>  [1] 1 4 1 2 5 3 2 3 3 1 5 5 2 2 1 5 5 1 1 5 5 2 2 1 4 1 4 3 2 2 4 4 4 2 4 1 1
 [38] 4 1 2 3 2 2 5 2 1 3 3 4 3 1 4 5 1 1 4 5 5 4 5 4 4 1 5 5 1 1 3 2 2 3 2 4 3
 [75] 5 2 2 1 3 3 2 2 5 2 5 4 5 4 1 3 2 3 3 1 5 4 4 1 5 5 1 3 3 3 3 4 1 1 4 2 1
[112] 2 3 4 1 3 5 3 4 2 1 4 1 4 2 5 2 2 2 3 1 2 3 3 3 3 5 3 1 2 4 2 2 4 5 1 5 5
[149] 5 4 4 4 2 1 3 1 1 4 5 1 3 4 5 4 1 1 5 5 1 5 4 2 2 1 5 5 2 5 2 4 2 5 5 4 4
[186] 1 2 4 1 1 3 1 1 4 3 5 3 5 1 1</code></pre>
</div>
</div>
<p>We use the <code>sample()</code> function to split the original data set into five folds. This creates a vector of random values between 1 through 5. This assigns the indices of <code>Datlab2</code> to each fold.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>k) <span class="co"># iterate from 1 through k=5</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>{ </span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># model of the train data portion of cv </span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>  M1CV<span class="ot">=</span><span class="fu">lm</span>(y<span class="sc">~</span> x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">*</span>x4,<span class="at">data=</span>Datlab2[folds<span class="sc">!=</span>j,]) </span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># obtain the performance (MSE) of the model M1CV by applying it to the test portion of cv  </span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>  M1CVMSE[j]<span class="ot">=</span><span class="fu">mean</span>((y<span class="sc">-</span><span class="fu">predict</span>(M1CV,Datlab2))[folds<span class="sc">==</span>j]<span class="sc">^</span><span class="dv">2</span>) }</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>k)</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>{ M2CV<span class="ot">=</span><span class="fu">lm</span>(y<span class="sc">~</span> x1 <span class="sc">+</span>x3<span class="sc">*</span>x4,<span class="at">data=</span>Datlab2[folds<span class="sc">!=</span>j,]) </span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>M2CVMSE[j]<span class="ot">=</span><span class="fu">mean</span>((y<span class="sc">-</span><span class="fu">predict</span>(M2CV,Datlab2))[folds<span class="sc">==</span>j]<span class="sc">^</span><span class="dv">2</span>) }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>During each iteration, the <code>Datlab2[folds!=j,]</code> selects indices that are not equal to the <span class="math inline">\(jth\)</span> iteration and assigns it as the train data and stores the model value in <code>M1CV</code>. So during the first iteration, the data train data will be all the indices that are not assigned to 1 in the <code>folds</code> vector.</p>
<p><code>[folds==j]</code> selects the indices that are equal to the <span class="math inline">\(jth\)</span> iteration, which is the test data. So, <code>(y-predict(M1CV,Datlab2))[folds==j]^2</code> is the standard error of the test data, which the difference between the actual values of <code>y</code> to the predicted values based on the model <code>M1CV</code>. MSE is calculated by obtaining the mean of the standard error in each iteration and is stored in <code>M2CVMSE[j]</code> where <code>j</code> is the current iteration index. <code>M2CVMSE</code> will then have 5 values since <code>j</code> has been set from 1 through <code>k=5</code>.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>MeanM1MSE<span class="ot">=</span><span class="fu">mean</span>(M1CVMSE) <span class="do">###CVMSE-M1###</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>MeanM2MSE<span class="ot">=</span><span class="fu">mean</span>(M2CVMSE) <span class="do">###CVMSE-M2###</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Finally, calculate the cross-validation MSE of <code>M1</code> (<a href="#eq-M1">Equation&nbsp;3</a>) and <code>M2</code> (<a href="#eq-M2">Equation&nbsp;4</a>) by obtaining the mean of each CV model.</p>
</section>
</section>
</section>
<section id="sec-3class1" class="level1">
<h1>Classification: Logistic Regression &amp; KNN</h1>
<section id="sec-3logistic" class="level2">
<h2 class="anchored" data-anchor-id="sec-3logistic">Logistic Regression</h2>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># clear global env (remove all stored obj) </span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>())</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="co"># load data</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>Default<span class="ot">=</span><span class="fu">read.csv</span>(<span class="at">file =</span> <span class="st">"../raw_data/Default.csv"</span>,</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>                 <span class="at">header=</span>T, <span class="at">stringsAsFactors=</span><span class="cn">TRUE</span>)</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(Default)</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a><span class="co"># check the dimensions</span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(Default)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 10000     4</code></pre>
</div>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(Default)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "default" "student" "balance" "income" </code></pre>
</div>
</div>
<p>Load Data <code>Default.csv</code> to object Default. The original data set contains 10000 observations.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>glm.fit1<span class="ot">=</span><span class="fu">glm</span>(default<span class="sc">~</span>balance<span class="sc">+</span>income<span class="sc">+</span>student,</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>             <span class="at">family=</span><span class="st">"binomial"</span>,</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">data=</span>Default)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>First, we can use the <code>glm()</code> function to fit model <code>glm.fit1</code> which includes all three independent variables: <code>student</code>, <code>balance</code> and <code>income</code>, with all the observations.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(glm.fit1)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(glm.fit1)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="fu">coef</span>(glm.fit1))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We can use the function <code>summary()</code> to obtain the coefficients, their associated p-values, model AIC and residual deviance. The function <code>exp()</code> calculates <strong>odds ratio</strong> of the coefficients.</p>
<section id="hold-out-logistic-regression-model" class="level3">
<h3 class="anchored" data-anchor-id="hold-out-logistic-regression-model">80/20 Hold-out Logistic Regression Model</h3>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 80/20 hold-out re-sampling</span></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="co"># indices of 80% train data </span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>train<span class="ot">=</span><span class="fu">sample</span>(<span class="fu">nrow</span>(Default),<span class="fu">nrow</span>(Default)<span class="sc">*</span><span class="fl">0.8</span>)</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="co"># indices 20% test data</span></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>Default.test<span class="ot">=</span>Default[<span class="sc">-</span>train, ]</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a><span class="co"># y-values (default variable) of the 20% test data</span></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>test.truevalue<span class="ot">=</span>default[<span class="sc">-</span>train]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We next evaluate the prediction accuracy of this model. We use the <code>sample()</code> function to split the original data set into one training set and one test set. We randomly select 80% of the observations for training and the remaining in the test set, <code>Default.test</code>. And save the true value of the testing set in the vector <code>test.truevalue</code>.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>glm.fit2<span class="ot">=</span><span class="fu">glm</span>(default<span class="sc">~</span>balance<span class="sc">+</span>student<span class="sc">+</span>income,</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>             <span class="at">data=</span>Default,</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">subset=</span>train,</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">family=</span>binomial)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We fit the data with all three independent variables into a logistic regression model <code>glm.fit2</code>. The <em><code>subset=train</code></em> option in <code>glm()</code> is to fit a regression using only the observations corresponding to the subset.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>glm.probs2<span class="ot">=</span><span class="fu">predict</span>(glm.fit2,Default.test, <span class="at">type=</span><span class="st">"response"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We evaluate the performance of the model using the test set (Default.test). We use the function <code>predict()</code> to calculate the <em>predicted probabilities</em> of the <strong>default</strong> in the test set and store them to <code>glm.pred2</code>. The <code>type="response"</code> option tells R to output probabilities not the logit.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">contrasts</span>(Default<span class="sc">$</span>default)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>    Yes
No    0
Yes   1</code></pre>
</div>
</div>
<p>R assigned <code>No=0</code> and <code>Yes=1</code> in the <code>default</code> variable. This means the our classifiers for the model is defined as:</p>
<p><span class="math display">\[\hat{C}(x) = \left\{
  \begin{matrix}
  1 \ \text{'above'} &amp; \hat{p}(x) &gt; 0.5 \\
  0 \ \text{'below'} &amp; \hat{p}(x) \le 0.5
  \end{matrix}
  \right.
\]</span></p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>glm.pred2<span class="ot">=</span><span class="fu">rep</span>(<span class="st">"No"</span>,<span class="dv">2000</span>)</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>glm.pred2[glm.probs2<span class="sc">&gt;</span>.<span class="dv">5</span>]<span class="ot">=</span><span class="st">"Yes"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We convert the predicted probabilities into a binary class label, <code>Yes</code> or <code>No</code>. The following commands create a vector of class predictions based on whether the predicted probability is greater than or less than <code>0.5</code>.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># a more concise code is to use ifelse()</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>glm.pred2<span class="ot">=</span><span class="fu">ifelse</span>(glm.probs2 <span class="sc">&gt;</span> <span class="fl">0.5</span>, <span class="st">'Yes'</span>, <span class="st">'No'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Based on the classifier, the predicted probabilities:</p>
<p><span class="math display">\[\hat{p}(x) = \hat{P}(Y=1 | X=x)\]</span></p>
<section id="sec-3accuracy" class="level4">
<h4 class="anchored" data-anchor-id="sec-3accuracy">Prediction Accuracy of 80/20 Hold-out</h4>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(glm.pred2,test.truevalue)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(glm.pred2<span class="sc">==</span>test.truevalue)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The <code>table()</code> function produce a <em>confusion matrix</em> to determine how many observations were correctly classified. We then use <code>mean()</code> function to calculate the <em>accuracy of the prediction</em>.</p>
</section>
</section>
<section id="cross-validation-logistic-regression-model" class="level3">
<h3 class="anchored" data-anchor-id="cross-validation-logistic-regression-model">Cross-Validation Logistic Regression Model</h3>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># set number of folds</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>k<span class="ot">=</span><span class="dv">5</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="co"># randomly assign indices to folds</span></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>folds<span class="ot">=</span><span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>k,<span class="fu">nrow</span>(Default),<span class="at">replace=</span><span class="cn">TRUE</span>)</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a><span class="co"># first 10 and last 10 fold values</span></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">head</span>(folds, <span class="at">n=</span><span class="dv">10</span>),<span class="st">"..."</span> ,<span class="fu">tail</span>(folds, <span class="at">n=</span><span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>2 4 4 5 5 1 4 1 2 1 ... 1 3 4 5 4 5 3 1 3 5</code></pre>
</div>
</div>
<p>We next evaluate the 5-fold cross-validation prediction of the model. Split data into k=5-folds. The output shows the first 10 and last 10 fold assignment. These are the first 10 and the last 10 rows (or index) of the data.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># zero vectors to hold accuracy values of cv method</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>accuracy<span class="ot">=</span><span class="fu">rep</span>(<span class="dv">0</span>,k)</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>k)</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># cv logistic reg model of train data</span></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>  glm.fit3<span class="ot">=</span><span class="fu">glm</span>(default<span class="sc">~</span>balance<span class="sc">+</span>student<span class="sc">+</span>income, </span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>               <span class="at">family=</span><span class="st">"binomial"</span>,</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>               <span class="at">data=</span>Default[folds<span class="sc">!=</span>i,])</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># assign the current ith iteration as the test data</span></span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>  Default.test<span class="ot">=</span>Default[folds<span class="sc">==</span>i, ]</span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>  <span class="co"># obtain the probabilities using the test data</span></span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a>  glm.probs3<span class="ot">=</span><span class="fu">predict</span>(glm.fit3,Default.test, </span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>                     <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a>  glm.pred3<span class="ot">=</span><span class="fu">rep</span>(<span class="st">"No"</span>, <span class="fu">nrow</span>(Default[folds<span class="sc">==</span>i,]))</span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a>  glm.pred3[glm.probs3<span class="sc">&gt;</span>.<span class="dv">5</span>]<span class="ot">=</span><span class="st">"yes"</span></span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a>  <span class="co"># y-value (default variable) of the test data in the ith iteration</span></span>
<span id="cb44-21"><a href="#cb44-21" aria-hidden="true" tabindex="-1"></a>  test.truevalue<span class="ot">=</span>default[folds<span class="sc">==</span>i]</span>
<span id="cb44-22"><a href="#cb44-22" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb44-23"><a href="#cb44-23" aria-hidden="true" tabindex="-1"></a>  <span class="co"># calculate the accuracy</span></span>
<span id="cb44-24"><a href="#cb44-24" aria-hidden="true" tabindex="-1"></a>  accuracy[i]<span class="ot">=</span><span class="fu">mean</span>(glm.pred3<span class="sc">==</span>test.truevalue)</span>
<span id="cb44-25"><a href="#cb44-25" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We create a vector to store the accuracy result for each fold. We set the initial values for this vector as zero. R treats logical <code>TRUE=1</code> and <code>FALSE=0</code>. So the <code>mean(glm.pred3==test.truevalue)</code> tests if the actual value of <code>default</code> is predicted accurately in <code>glm.pred3</code> in each row. If they match up, then the return value is TRUE=1, if they do not, then the return value is FALSE=0. At each iteration, the prediction accuracy calculated by obtaining the average and is stored into <code>accuracy[i]</code></p>
</section>
<section id="prediction-accuracy-of-cv-logistic-regression" class="level3">
<h3 class="anchored" data-anchor-id="prediction-accuracy-of-cv-logistic-regression">Prediction Accuracy of CV Logistic Regression</h3>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(accuracy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Then we calculate the accuracy of the CV Logistic model by obtaining the grand average accuracy.</p>
</section>
</section>
<section id="knn" class="level2">
<h2 class="anchored" data-anchor-id="knn">KNN</h2>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(class)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="data-scaling" class="level3">
<h3 class="anchored" data-anchor-id="data-scaling">Data Scaling</h3>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>standardized.balance<span class="ot">=</span><span class="fu">scale</span>(balance)</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>standardized.income<span class="ot">=</span><span class="fu">scale</span>(income)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We first normalize the two quantitative input variables balance and income so that they would be on a comparable scale. The function <code>scale()</code> <strong>standardizes</strong> the quantitative variables.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>Input.standard<span class="ot">=</span><span class="fu">cbind</span>(standardized.balance,standardized.income,student)</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>accuracy<span class="ot">=</span><span class="fu">matrix</span>(<span class="dv">0</span>,<span class="dv">10</span>,<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Then we use the function <code>cbind()</code> to combine the two standardized variables and the qualitative input variable together.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>folds<span class="ot">=</span><span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,<span class="fu">nrow</span>(Input.standard),<span class="at">replace=</span><span class="cn">TRUE</span>)</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>) <span class="co"># 10 neighbors considered</span></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>) <span class="co"># for each fold</span></span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>  {</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># train data indices </span></span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>    train.standard<span class="ot">=</span>Input.standard[folds<span class="sc">!=</span>i,]</span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># test data indices</span></span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a>    test.standard<span class="ot">=</span>Input.standard[folds<span class="sc">==</span>i,]</span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># y-values (default var) of train data</span></span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a>    train.truevalue<span class="ot">=</span>default[folds<span class="sc">!=</span>i]</span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># y-values (default var) of test data </span></span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a>    test.truevalue<span class="ot">=</span>default[folds<span class="sc">==</span>i]</span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb49-18"><a href="#cb49-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb49-19"><a href="#cb49-19" aria-hidden="true" tabindex="-1"></a>    knn.pred<span class="ot">=</span><span class="fu">knn</span>(<span class="at">train=</span>train.standard,</span>
<span id="cb49-20"><a href="#cb49-20" aria-hidden="true" tabindex="-1"></a>                 <span class="at">test=</span>test.standard,</span>
<span id="cb49-21"><a href="#cb49-21" aria-hidden="true" tabindex="-1"></a>                 <span class="at">cl=</span>train.truevalue,</span>
<span id="cb49-22"><a href="#cb49-22" aria-hidden="true" tabindex="-1"></a>                 <span class="at">k=</span>j)</span>
<span id="cb49-23"><a href="#cb49-23" aria-hidden="true" tabindex="-1"></a>    accuracy[j,i]<span class="ot">=</span><span class="fu">mean</span>(knn.pred<span class="sc">==</span>test.truevalue)</span>
<span id="cb49-24"><a href="#cb49-24" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb49-25"><a href="#cb49-25" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>To use KNN, we need to determine K. We can use 5-fold cross-validation to select the best K from <code>[1,10]</code>. Thus, we first create a matrix to store the accuracy results for five folds and ten different K values. We set the initial values for this matrix as zero.</p>
<p><code>train.standard</code> is the input matrix of the training set and test.standard is the input matrix of the testing set. <code>train.truevalue</code> is the original value of default in the training set and <code>test.truevalue</code> is the true value of default in the testing set. For each observation in the testing set, the knn function can calculate its distance with each observation in the training set based on <code>train.standard</code> and <code>test.standard</code>. Given <code>k=j</code>, it selects the <code>k</code> most nearest neighbors, and use their default values (based on <code>train.truevalue</code>) to predict the default values in the testing set. In the knn function, we specify the number of neighbors in the option <code>k=j</code>. The output of this loop is the prediction accuracy</p>
</section>
<section id="accuracy-of-knn-model" class="level3">
<h3 class="anchored" data-anchor-id="accuracy-of-knn-model">Accuracy of KNN Model</h3>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>cv.accuracy<span class="ot">=</span><span class="fu">apply</span>(accuracy,<span class="dv">1</span>,mean)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Then we calculate the average cross-validation accuracy for each <code>K</code>.</p>
</section>
</section>
</section>
<section id="sec-4class2" class="level1">
<h1>Classification: CART, Bagging &amp; Random Forest</h1>
<section id="load-data" class="level2">
<h2 class="anchored" data-anchor-id="load-data">Load Data</h2>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>())</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tree)</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>iris<span class="ot">&lt;-</span><span class="fu">read.csv</span>(<span class="at">file=</span><span class="st">"../raw_data/iris.csv"</span>,</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>               <span class="at">header=</span>T, </span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>               <span class="at">stringsAsFactors=</span><span class="cn">TRUE</span>)</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(iris)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Sepal.Length" "Sepal.Width"  "Petal.Length" "Petal.Width"  "Species"     </code></pre>
</div>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(iris)</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(iris)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   
 Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  
 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  
 Median :5.800   Median :3.000   Median :4.350   Median :1.300  
 Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  
 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  
 Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  
       Species  
 setosa    :50  
 versicolor:50  
 virginica :50  
                
                
                </code></pre>
</div>
</div>
<p>It contains 3 classes of a total 150 instances. Each class refers to a type of iris plant.</p>
</section>
<section id="hold-out-classification-tree" class="level2">
<h2 class="anchored" data-anchor-id="hold-out-classification-tree">80/20 Hold-out Classification Tree</h2>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># reproduceable random sampling seed</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a><span class="co"># indices of the traning data (80%)</span></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>train<span class="ot">=</span><span class="fu">sample</span>(<span class="fu">nrow</span>(iris),<span class="fu">nrow</span>(iris)<span class="sc">*</span><span class="fl">0.8</span>)</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a><span class="co"># tree model of the training data</span></span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a>tree.model<span class="ot">=</span><span class="fu">tree</span>(Species<span class="sc">~</span>.,iris,<span class="at">subset =</span>train)</span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a><span class="co"># indices of the test data (20%)</span></span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a>iris.test<span class="ot">=</span>iris[<span class="sc">-</span>train,]</span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a><span class="co"># values of the target variable (Species variable)</span></span>
<span id="cb55-14"><a href="#cb55-14" aria-hidden="true" tabindex="-1"></a>Species.test<span class="ot">=</span>Species[<span class="sc">-</span>train]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We first create a training set, and fit the tree using the training set.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>cv.model<span class="ot">=</span><span class="fu">cv.tree</span>(<span class="at">object=</span>tree.model, </span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>                 <span class="at">K=</span><span class="dv">10</span>, <span class="co"># k-fold cross validation</span></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>                 <span class="at">FUN=</span>prune.misclass)</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>cv.model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We use <code>cv.tree()</code> to perform 10-fold cross validation, <code>K=10</code>, to find the best subtree or the optimal way to prune the tree. Although the re-sampling method is 80/20 holdout, <code>cv.tree()</code> does cross validation internally.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># prune tree model</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>prune.model<span class="ot">=</span><span class="fu">prune.tree</span>(<span class="at">tree=</span>tree.model,</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>                       <span class="at">best=</span><span class="dv">5</span>) <span class="co"># number of terminal nodes</span></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(prune.model)</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(prune.model,<span class="at">pretty=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We prune tree to the size with the lowest cross-validation error rate using the <code>prune.tree()</code> function and plot the tree. We use the argument <code>FUN=prune.misclass</code> since it is the classification tree. It indicates that we want the classification error rate to guide the cross-validation and pruning process, rather than the default - deviance.</p>
<section id="performance-by-confusion-matrix" class="level3">
<h3 class="anchored" data-anchor-id="performance-by-confusion-matrix">Performance by Confusion Matrix</h3>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>prunetree.pred<span class="ot">=</span><span class="fu">predict</span>(prune.model, <span class="co"># pruned tree model</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>                       iris.test, <span class="co"># apply pruned tree model on test data</span></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>                       <span class="at">type=</span><span class="st">"class"</span>) <span class="co"># classification</span></span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(prunetree.pred,Species.test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Then we use the pruned tree to make predictions in the testing set and calculate the confusion matrix.</p>
</section>
</section>
<section id="regression-tree" class="level2">
<h2 class="anchored" data-anchor-id="regression-tree">Regression Tree</h2>
<section id="load-data-1" class="level3">
<h3 class="anchored" data-anchor-id="load-data-1">Load data</h3>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>())</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tree)</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>Boston<span class="ot">=</span><span class="fu">read.csv</span>(<span class="st">"../raw_data/Boston.csv"</span>,<span class="at">header=</span>T)</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Boston)</span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(Boston)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Load Data <code>Boston.csv</code> to object Boston load package <code>tree</code> again.</p>
</section>
<section id="regression-tree-model" class="level3">
<h3 class="anchored" data-anchor-id="regression-tree-model">Regression Tree Model</h3>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 50/50 holdout resampling</span></span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(Boston), <span class="fu">nrow</span>(Boston)<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>tree.boston<span class="ot">=</span><span class="fu">tree</span>(medv<span class="sc">~</span>.,Boston,<span class="at">subset=</span>train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>There are 506 records with one continuous response <code>medv</code> (median house value) and 13 predictors. We again create a training set.</p>
</section>
<section id="best-sub-tree-model" class="level3">
<h3 class="anchored" data-anchor-id="best-sub-tree-model">Best Sub-Tree Model</h3>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>cv.boston<span class="ot">=</span><span class="fu">cv.tree</span>(<span class="at">object=</span>tree.boston,</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">K=</span><span class="dv">10</span>) <span class="co"># k-fold cross-validation</span></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>cv.boston</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We use the <code>cv.tree()</code> function to perform 10-fold cross validation to find the best subtree. <em>We do not need to specify the argument FUN since it is the regression tree.</em></p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>prune.boston<span class="ot">=</span><span class="fu">prune.tree</span>(tree.boston,</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>                        <span class="at">best=</span><span class="dv">8</span>) <span class="co"># number of terminal nodes</span></span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(prune.boston)</span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(prune.boston,<span class="at">pretty=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We prune tree to the optimal size using the <code>prune.tree()</code> function and plot the tree.</p>
</section>
<section id="tree-model-performance" class="level3">
<h3 class="anchored" data-anchor-id="tree-model-performance">Tree Model Performance</h3>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># assign vector of the target variable medv as test data</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>boston.test<span class="ot">=</span>Boston[<span class="sc">-</span>train,<span class="st">"medv"</span>] </span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>tree.pred<span class="ot">=</span><span class="fu">predict</span>(prune.boston, <span class="co"># pruned tree model</span></span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a>                  <span class="at">newdata=</span>Boston[<span class="sc">-</span>train,]) <span class="co"># test data</span></span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate MSE</span></span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>((tree.pred<span class="sc">-</span>boston.test)<span class="sc">^</span><span class="dv">2</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Then we use the pruned tree to make predictions in the testing set and calculate the mean square error (MSE).</p>
</section>
</section>
<section id="random-forests-full-model" class="level2">
<h2 class="anchored" data-anchor-id="random-forests-full-model">Random Forests (FULL) Model</h2>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>bag.boston<span class="ot">=</span><span class="fu">randomForest</span>(medv<span class="sc">~</span>., <span class="co"># target/response variable</span></span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>                        <span class="at">data=</span>Boston, <span class="co"># df containing the variable of the model</span></span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a>                        <span class="at">subset=</span>train, <span class="co"># train dataset to model</span></span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a>                        <span class="at">mtry=</span><span class="dv">13</span>, <span class="co"># number of predictors to use (all 13)</span></span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a>                        <span class="at">importance=</span><span class="cn">TRUE</span>)</span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a>bag.boston</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>In the <code>randomForest()</code> function, the argument <code>mtry=13</code> indicates that <em>all 13 predictors</em> should be used, that is bagging. <code>subset=train</code> indicates that we train this model only using the training dataset. <code>importance=TRUE</code> indicates that the importance of predictors is assessed. <code>bag.boston</code> stores the bagging model.</p>
<section id="random-forest-full-model-performance" class="level3">
<h3 class="anchored" data-anchor-id="random-forest-full-model-performance">Random Forest (FULL) Model Performance</h3>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>yhat.bag <span class="ot">=</span> <span class="fu">predict</span>(bag.boston, <span class="co"># rf model</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>                   <span class="at">newdata=</span>Boston[<span class="sc">-</span>train,]) <span class="co"># test data</span></span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate MSE mean sq. of the difference predicted and actual</span></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>((yhat.bag<span class="sc">-</span>boston.test)<span class="sc">^</span><span class="dv">2</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We next evaluate the performance of bagging by fitting it to the testing dataset Boston[-train,]. Then we calculate the MSE.</p>
</section>
<section id="random-forest-model" class="level3">
<h3 class="anchored" data-anchor-id="random-forest-model">Random Forest Model</h3>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a><span class="co"># target response medv against any 5 predictors (mtry=5)</span></span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>rf.boston<span class="ot">=</span><span class="fu">randomForest</span>(medv<span class="sc">~</span>.,</span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a>                       <span class="at">data=</span>Boston,</span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a>                       <span class="at">subset=</span>train,</span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a>                       <span class="at">mtry=</span><span class="dv">5</span>, <span class="co"># rf regression uses 1/3 of total predictors</span></span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a>                       <span class="at">importance=</span><span class="cn">TRUE</span>)</span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-10"><a href="#cb66-10" aria-hidden="true" tabindex="-1"></a>yhat.rf <span class="ot">=</span> <span class="fu">predict</span>(rf.boston,<span class="at">newdata=</span>Boston[<span class="sc">-</span>train,])</span>
<span id="cb66-11"><a href="#cb66-11" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>((yhat.rf<span class="sc">-</span>boston.test)<span class="sc">^</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Now let’s use the function to implement random forest. The <em>difference is that random forest does not use all input variables in each tree</em>. It usually uses <strong>p/3 variables for regression trees</strong> and <strong><span class="math inline">\(\sqrt{p}\)</span> for classification trees</strong>. Now let’s use <code>mtry=5</code>. <code>rf.boston</code> stores the random forest model. We test the MSE of this model by comparing the predicted values with the true values.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="fu">importance</span>(rf.boston)</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a><span class="fu">varImpPlot</span>(rf.boston)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The importance of each variable can be evaluated using the <code>importance()</code> function. The function <code>varImpPlot()</code> plots the important measures. Two measures of variable importance are reported. One is based on the mean decrease of accuracy in predictions on the out of bag samples when a given variable is excluded from the model. The second is a measure of the total decrease in node impurity that results from splits over that variable, averaged over all trees.</p>
</section>
</section>
</section>
<section id="clustering" class="level1">
<h1>Clustering</h1>
<section id="load-data-2" class="level2">
<h2 class="anchored" data-anchor-id="load-data-2">Load Data</h2>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>iris<span class="ot">&lt;-</span><span class="fu">read.csv</span>(<span class="st">"../raw_data/iris.csv"</span>,</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>               <span class="at">header=</span>T,</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">stringsAsFactors=</span><span class="cn">TRUE</span>)</span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(iris)</span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(iris)</span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(iris)</span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(iris)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><code>iris.csv</code> is a multivariate data set introduced by Ronald Fisher (1936): The use of multiple measurements in taxonomic problem. It contains 3 classes of a total 150 instances. Each class refers to a type of iris plant. There are five variables in this data set: <code>Sepal.Length, Sepal.Width, Petal.Length, Petal.Width and Species</code>.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>iris.labs<span class="ot">=</span>iris[,<span class="dv">5</span>]</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>iris.data<span class="ot">=</span>iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>]</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(iris.data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 150   4</code></pre>
</div>
</div>
<p>Each instance is labeled with a class. We do not use the class in performing clustering, as it is an unsupervised technique. But after performing clustering, we can check the extent to which these classes agree with the result of the unsupervised technique. Accordingly, we store the label of each instance in the object <code>iris.labs</code>.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(iris.labs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>iris.labs
    setosa versicolor  virginica 
        50         50         50 </code></pre>
</div>
</div>
<p><code>table(iris.labs)</code> shows that we have 50 instances in each class.</p>
<section id="euclidean-distance-method" class="level3">
<h3 class="anchored" data-anchor-id="euclidean-distance-method">Euclidean Distance Method</h3>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>data.dist<span class="ot">=</span><span class="fu">dist</span>(iris.data,</span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>               <span class="at">method =</span> <span class="st">'euclidean'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Since clustering relies on the distances between clusters, we use the function <code>dist()</code> to compute the <span class="math inline">\(150 \times 150\)</span> inter-observation Euclidean distance matrix and store it in the object <code>data.dist</code>.</p>
<section id="hierarchical-clustering" class="level4">
<h4 class="anchored" data-anchor-id="hierarchical-clustering">Hierarchical Clustering</h4>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co"># default uses complete linkage</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>hc1<span class="ot">=</span><span class="fu">hclust</span>(<span class="at">d=</span>data.dist)</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a><span class="co"># average linkage </span></span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>hc2<span class="ot">=</span><span class="fu">hclust</span>(<span class="at">d=</span>data.dist, </span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a>           <span class="at">method=</span><span class="st">"average"</span>)</span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a><span class="co"># single linkage</span></span>
<span id="cb74-9"><a href="#cb74-9" aria-hidden="true" tabindex="-1"></a>hc3<span class="ot">=</span><span class="fu">hclust</span>(<span class="at">d=</span>data.dist, </span>
<span id="cb74-10"><a href="#cb74-10" aria-hidden="true" tabindex="-1"></a>           <span class="at">method=</span><span class="st">"single"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The <code>hclust()</code> function implements hierarchical clustering. The first parameter in this function is the dissimilarity structure <code>d=data.dist</code>, i.e.&nbsp;the distance matrix. The second parameter <code>method=</code> is the linkage type, e.g.&nbsp;average, complete, single, or centroid. By default, it is the “complete” linkage type. Thus, hc1 stores the clustering dendrogram using the complete linkage clustering.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="co"># combine plots in 1x3 display </span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>)) </span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(hc1, <span class="at">main=</span><span class="st">"Complete Linkage"</span>, <span class="at">xlab=</span><span class="st">""</span>, <span class="at">sub=</span><span class="st">""</span>,<span class="at">ylab=</span><span class="st">""</span>)</span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(hc2, <span class="at">main=</span><span class="st">"Average Linkage"</span>, <span class="at">xlab=</span><span class="st">""</span>, <span class="at">sub=</span><span class="st">""</span>,<span class="at">ylab=</span><span class="st">""</span>)</span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(hc3, <span class="at">main=</span><span class="st">"Single Linkage"</span>, <span class="at">xlab=</span><span class="st">""</span>, <span class="at">sub=</span><span class="st">""</span>,<span class="at">ylab=</span><span class="st">""</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We plot the obtained dendrograms using the <code>plot()</code> function. The numbers at the bottom of the plot identify each observation. We could see that the choice of linkage certainly affect the results obtained.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>hc.clusters1<span class="ot">=</span><span class="fu">cutree</span>(hc1,<span class="dv">3</span>)</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>hc.clusters2<span class="ot">=</span><span class="fu">cutree</span>(hc2,<span class="dv">3</span>)</span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a>hc.clusters3<span class="ot">=</span><span class="fu">cutree</span>(hc3,<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We need to determine where to cut the dendrogram so as to identify the labels for each observation. This decision has a strong impact on the clustering results. We usually need to try several choices, and use the one with the highest interpretability. In this case, as we already know there are a total of three classes, we can cut them to obtain three clusters using the <code>cutree()</code> function.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(hc.clusters1,iris.labs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>            iris.labs
hc.clusters1 setosa versicolor virginica
           1     50          0         0
           2      0         23        49
           3      0         27         1</code></pre>
</div>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(hc.clusters2,iris.labs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>            iris.labs
hc.clusters2 setosa versicolor virginica
           1     50          0         0
           2      0         50        14
           3      0          0        36</code></pre>
</div>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(hc.clusters3,iris.labs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>            iris.labs
hc.clusters3 setosa versicolor virginica
           1     50          0         0
           2      0         50        48
           3      0          0         2</code></pre>
</div>
</div>
<p>We then compare the cluster labels from all three methods with the original labels. All three linkage methods successfully identify all the flowers of species setosa into cluster 1. But they do not differentiate between virginica and versicolor quite well. The average linkage type looks better than the other two types.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="co"># display 2 plots in 1x2 format</span></span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a><span class="co"># set color configuration</span></span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a>cols <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"red"</span>,<span class="st">"green"</span>,<span class="st">"blue"</span>)</span>
<span id="cb83-6"><a href="#cb83-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-7"><a href="#cb83-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(Sepal.Width <span class="sc">~</span> Sepal.Length, </span>
<span id="cb83-8"><a href="#cb83-8" aria-hidden="true" tabindex="-1"></a>     <span class="at">data=</span>iris, </span>
<span id="cb83-9"><a href="#cb83-9" aria-hidden="true" tabindex="-1"></a>     <span class="at">col=</span>cols[iris<span class="sc">$</span>Species], </span>
<span id="cb83-10"><a href="#cb83-10" aria-hidden="true" tabindex="-1"></a>     <span class="at">main=</span><span class="st">"Sepal.Width ~ Sepal.Length"</span>)</span>
<span id="cb83-11"><a href="#cb83-11" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="at">x=</span><span class="fl">6.5</span>, <span class="at">y=</span><span class="fl">4.5</span>, </span>
<span id="cb83-12"><a href="#cb83-12" aria-hidden="true" tabindex="-1"></a>       <span class="at">legend=</span><span class="fu">levels</span>(iris<span class="sc">$</span>Species), </span>
<span id="cb83-13"><a href="#cb83-13" aria-hidden="true" tabindex="-1"></a>       <span class="at">col=</span>cols, </span>
<span id="cb83-14"><a href="#cb83-14" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch=</span><span class="dv">1</span>)</span>
<span id="cb83-15"><a href="#cb83-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-16"><a href="#cb83-16" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(Petal.Width <span class="sc">~</span> Petal.Length, </span>
<span id="cb83-17"><a href="#cb83-17" aria-hidden="true" tabindex="-1"></a>     <span class="at">data=</span>iris, </span>
<span id="cb83-18"><a href="#cb83-18" aria-hidden="true" tabindex="-1"></a>     <span class="at">col=</span>cols[iris<span class="sc">$</span>Species],</span>
<span id="cb83-19"><a href="#cb83-19" aria-hidden="true" tabindex="-1"></a>     <span class="at">main=</span><span class="st">"Petal.Width ~ Petal.Length"</span>)</span>
<span id="cb83-20"><a href="#cb83-20" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="at">x=</span><span class="dv">1</span>, <span class="at">y=</span><span class="fl">2.5</span>, </span>
<span id="cb83-21"><a href="#cb83-21" aria-hidden="true" tabindex="-1"></a>       <span class="at">legend=</span><span class="fu">levels</span>(iris<span class="sc">$</span>Species), </span>
<span id="cb83-22"><a href="#cb83-22" aria-hidden="true" tabindex="-1"></a>       <span class="at">col=</span>cols, </span>
<span id="cb83-23"><a href="#cb83-23" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="labcompilation_files/figure-html/unnamed-chunk-65-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Based on the above two plots, variables Petal.Length and Petal.Width can better differentiate among the three species. Thus, we re-design all three clustering models using the only two variables.</p>
</section>
</section>
<section id="hierarchical-clustering-model-comparison-on-selected-variables" class="level3">
<h3 class="anchored" data-anchor-id="hierarchical-clustering-model-comparison-on-selected-variables">Hierarchical Clustering Model Comparison on Selected Variables</h3>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="co"># include only Petal.Length and Petal.Width</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>iris.data2<span class="ot">=</span>iris[,<span class="dv">3</span><span class="sc">:</span><span class="dv">4</span>]</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Euclidean distance </span></span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a>data.dist2<span class="ot">=</span><span class="fu">dist</span>(iris.data2, </span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a>                <span class="at">method =</span> <span class="st">'euclidean'</span>)</span>
<span id="cb84-7"><a href="#cb84-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-8"><a href="#cb84-8" aria-hidden="true" tabindex="-1"></a><span class="co"># cluster model default is method=complete</span></span>
<span id="cb84-9"><a href="#cb84-9" aria-hidden="true" tabindex="-1"></a>newhc1<span class="ot">=</span><span class="fu">hclust</span>(data.dist2)</span>
<span id="cb84-10"><a href="#cb84-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-11"><a href="#cb84-11" aria-hidden="true" tabindex="-1"></a><span class="co"># average linkage</span></span>
<span id="cb84-12"><a href="#cb84-12" aria-hidden="true" tabindex="-1"></a>newhc2<span class="ot">=</span><span class="fu">hclust</span>(data.dist2, <span class="at">method=</span><span class="st">"average"</span>)</span>
<span id="cb84-13"><a href="#cb84-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-14"><a href="#cb84-14" aria-hidden="true" tabindex="-1"></a><span class="co"># single linkage</span></span>
<span id="cb84-15"><a href="#cb84-15" aria-hidden="true" tabindex="-1"></a>newhc3<span class="ot">=</span><span class="fu">hclust</span>(data.dist2, <span class="at">method=</span><span class="st">"single"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Re-design all three clustering models using the only two variables.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make it into 3 clusters (groups)</span></span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>newhc.clusters1<span class="ot">=</span><span class="fu">cutree</span>(newhc1,<span class="dv">3</span>)</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>newhc.clusters2<span class="ot">=</span><span class="fu">cutree</span>(newhc2,<span class="dv">3</span>)</span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>newhc.clusters3<span class="ot">=</span><span class="fu">cutree</span>(newhc3,<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Make into 3 cluster groups on all three methods</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co"># analyze difference between difference hierarchical methods</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a><span class="co"># complete linkage</span></span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(newhc.clusters1,iris.labs) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>               iris.labs
newhc.clusters1 setosa versicolor virginica
              1     50          0         0
              2      0         21        50
              3      0         29         0</code></pre>
</div>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="co"># average linkage</span></span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(newhc.clusters2,iris.labs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>               iris.labs
newhc.clusters2 setosa versicolor virginica
              1     50          0         0
              2      0         45         1
              3      0          5        49</code></pre>
</div>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="co"># single linkage</span></span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(newhc.clusters3,iris.labs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>               iris.labs
newhc.clusters3 setosa versicolor virginica
              1     50          0         0
              2      0         49        50
              3      0          1         0</code></pre>
</div>
</div>
<p>Now we can see that the clustering algorithm with the average linkage does a much better job. Only five observations in versicolor and one in virginica do not fall in their own cluster.</p>
</section>
<section id="plot-the-best-method-average-linkage" class="level3">
<h3 class="anchored" data-anchor-id="plot-the-best-method-average-linkage">Plot the best method, Average Linkage</h3>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(newhc2, <span class="at">labels=</span>iris.labs)</span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="fl">1.3</span>, <span class="at">col=</span><span class="st">"red"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="labcompilation_files/figure-html/unnamed-chunk-69-1.png" class="img-fluid" width="672"></p>
</div>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a>newhc2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
hclust(d = data.dist2, method = "average")

Cluster method   : average 
Distance         : euclidean 
Number of objects: 150 </code></pre>
</div>
</div>
</section>
</section>
<section id="k-means-clustering" class="level2">
<h2 class="anchored" data-anchor-id="k-means-clustering">K-Means Clustering</h2>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>km.out1 <span class="ot">=</span><span class="fu">kmeans</span>(iris.data,</span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a>                <span class="at">centers=</span><span class="dv">3</span>, <span class="co"># number of k-clusters</span></span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a>                <span class="at">nstart=</span><span class="dv">1</span>) <span class="co"># how many random sets</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>In Step 1 of K-means, the initial cluster labels are assigned randomly, we first set a random seed. The function <code>kmeans()</code> performs K-means clustering. The first parameter is the data matrix. The second one is the pre-specified <code>K</code>, the number of clusters. In this case, we set it as 3. The third parameter, <code>nstart</code>, indicates the number of random assignments in Step 1. We first set <code>nstart=1</code>, which means that only run the function with one set of initial cluster assignment.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>km.out1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>K-means clustering with 3 clusters of sizes 62, 38, 50

Cluster means:
  Sepal.Length Sepal.Width Petal.Length Petal.Width
1     5.901613    2.748387     4.393548    1.433871
2     6.850000    3.073684     5.742105    2.071053
3     5.006000    3.428000     1.462000    0.246000

Clustering vector:
  [1] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
 [38] 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [75] 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2 1 2 2 2 2
[112] 2 2 1 1 2 2 2 2 1 2 1 2 1 2 2 1 1 2 2 2 2 2 1 2 2 2 2 1 2 2 2 1 2 2 2 1 2
[149] 2 1

Within cluster sum of squares by cluster:
[1] 39.82097 23.87947 15.15100
 (between_SS / total_SS =  88.4 %)

Available components:

[1] "cluster"      "centers"      "totss"        "withinss"     "tot.withinss"
[6] "betweenss"    "size"         "iter"         "ifault"      </code></pre>
</div>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>km.out1<span class="sc">$</span>cluster</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>  [1] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
 [38] 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [75] 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2 1 2 2 2 2
[112] 2 2 1 1 2 2 2 2 1 2 1 2 1 2 2 1 1 2 2 2 2 2 1 2 2 2 2 1 2 2 2 1 2 2 2 1 2
[149] 2 1</code></pre>
</div>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>km.out1<span class="sc">$</span>betweenss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 602.5192</code></pre>
</div>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>km.out1<span class="sc">$</span>withinss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 39.82097 23.87947 15.15100</code></pre>
</div>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>km.out1<span class="sc">$</span>tot.withinss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 78.85144</code></pre>
</div>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>km.out1<span class="sc">$</span>totss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 681.3706</code></pre>
</div>
</div>
<p>The kmeans function returns multiple values. <code>km.out1$cluster</code> returns the clustering results. <code>km.out1$betweenss</code> returns the between-cluster sum of squares. <code>km.out1$withinss</code> returns the within-cluster sum of squares for each cluster. <code>km.out1$tot.withinss</code> returns the total within-cluster sum of squares across all K clusters. <code>km.out1$totss</code>returns the total sum of squares in this data set.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(km.out1<span class="sc">$</span>cluster,iris.labs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We compare the cluster labels with the original labels by using the function <code>table()</code>.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">3</span>)</span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a>km.out2<span class="ot">=</span><span class="fu">kmeans</span>(iris.data,</span>
<span id="cb109-3"><a href="#cb109-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">centers=</span><span class="dv">3</span>, <span class="co"># number of k-clusters</span></span>
<span id="cb109-4"><a href="#cb109-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">nstart=</span><span class="dv">1</span>) <span class="co"># how many random sets</span></span>
<span id="cb109-5"><a href="#cb109-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-6"><a href="#cb109-6" aria-hidden="true" tabindex="-1"></a>km.out2<span class="sc">$</span>betweenss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 538.6171</code></pre>
</div>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a>km.out2<span class="sc">$</span>withinss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1]   6.432121 118.651875  17.669524</code></pre>
</div>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>km.out2<span class="sc">$</span>tot.withinss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 142.7535</code></pre>
</div>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a>km.out2<span class="sc">$</span>totss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 681.3706</code></pre>
</div>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(km.out2<span class="sc">$</span>cluster,iris.labs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>   iris.labs
    setosa versicolor virginica
  1     33          0         0
  2      0         46        50
  3     17          4         0</code></pre>
</div>
</div>
<p>Now let’s explore if the initial cluster assignment affects the clustering results. We set a different random seed for Step 1 and then re-run the algorithm. Do we get the same clustering results? Doe the total within cluster sum of squares change? Does the total sum of squares change?</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb119-2"><a href="#cb119-2" aria-hidden="true" tabindex="-1"></a>km.out3 <span class="ot">=</span><span class="fu">kmeans</span>(iris.data, </span>
<span id="cb119-3"><a href="#cb119-3" aria-hidden="true" tabindex="-1"></a>                <span class="at">centers=</span><span class="dv">3</span>, <span class="co"># number of k-cluster</span></span>
<span id="cb119-4"><a href="#cb119-4" aria-hidden="true" tabindex="-1"></a>                <span class="at">nstart=</span><span class="dv">20</span>) <span class="co"># how many random sets</span></span>
<span id="cb119-5"><a href="#cb119-5" aria-hidden="true" tabindex="-1"></a>km.out3<span class="sc">$</span>betweenss</span>
<span id="cb119-6"><a href="#cb119-6" aria-hidden="true" tabindex="-1"></a>km.out3<span class="sc">$</span>withinss</span>
<span id="cb119-7"><a href="#cb119-7" aria-hidden="true" tabindex="-1"></a>km.out3<span class="sc">$</span>tot.withinss</span>
<span id="cb119-8"><a href="#cb119-8" aria-hidden="true" tabindex="-1"></a>km.out3<span class="sc">$</span>totss</span>
<span id="cb119-9"><a href="#cb119-9" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(km.out3<span class="sc">$</span>cluster,iris.labs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We use nstart=1in the previous two models. If a value of nstart greater than one is used, then K-means clustering will be performed using multiple random assignments. It reports only the best results in terms of the total within-cluster sum of squares. Now let’s try <code>nstart=20</code>. In practice, we usually try a larger value of <code>nstart</code>, e.g.&nbsp;20, 50, to obtain the optimal model. Do we get the same clustering results as the previous two models? Doe the total within-cluster sum of squares change? Does the total sum of squares change?</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a>iris.data2<span class="ot">=</span>iris[,<span class="dv">3</span><span class="sc">:</span><span class="dv">4</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>As we learnt in hierarchical clustering, variables Petal.Length and Petal.Width can better differentiate among the three species. Thus, we run models using the only two variables.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-3"><a href="#cb121-3" aria-hidden="true" tabindex="-1"></a><span class="co"># scale data</span></span>
<span id="cb121-4"><a href="#cb121-4" aria-hidden="true" tabindex="-1"></a>sd.data<span class="ot">=</span><span class="fu">scale</span>(iris.data2)</span>
<span id="cb121-5"><a href="#cb121-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-6"><a href="#cb121-6" aria-hidden="true" tabindex="-1"></a>km.out4<span class="ot">=</span><span class="fu">kmeans</span>(sd.data,</span>
<span id="cb121-7"><a href="#cb121-7" aria-hidden="true" tabindex="-1"></a>                <span class="at">centers=</span><span class="dv">3</span>, <span class="co"># number of k-clusters</span></span>
<span id="cb121-8"><a href="#cb121-8" aria-hidden="true" tabindex="-1"></a>                <span class="at">nstart =</span><span class="dv">20</span>) <span class="co"># how many random sets</span></span>
<span id="cb121-9"><a href="#cb121-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-10"><a href="#cb121-10" aria-hidden="true" tabindex="-1"></a>km.out4<span class="sc">$</span>betweenss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 280.0932</code></pre>
</div>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb123"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a>km.out4<span class="sc">$</span>withinss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 9.293174 7.202739 1.410870</code></pre>
</div>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a>km.out4<span class="sc">$</span>tot.withinss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 17.90678</code></pre>
</div>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>km.out4<span class="sc">$</span>totss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 298</code></pre>
</div>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(km.out4<span class="sc">$</span>cluster,iris.labs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>   iris.labs
    setosa versicolor virginica
  1      0          2        46
  2      0         48         4
  3     50          0         0</code></pre>
</div>
</div>
<p>If we intend to standardize the variables to have mean zero and standard deviation one, we can use the <code>scale()</code> function. Again, do we get the same clustering results as the previous two models? Doe the total within-cluster sum of squares change? Does the total sum of squares change? Why?</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a>km.out5<span class="ot">=</span><span class="fu">kmeans</span>(iris.data2,</span>
<span id="cb131-2"><a href="#cb131-2" aria-hidden="true" tabindex="-1"></a>               <span class="at">centers=</span><span class="dv">3</span>, <span class="co"># number of k-clusters </span></span>
<span id="cb131-3"><a href="#cb131-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">nstart=</span><span class="dv">20</span>) <span class="co"># how many random</span></span>
<span id="cb131-4"><a href="#cb131-4" aria-hidden="true" tabindex="-1"></a>km.out5<span class="sc">$</span>betweenss</span>
<span id="cb131-5"><a href="#cb131-5" aria-hidden="true" tabindex="-1"></a>km.out5<span class="sc">$</span>withinss</span>
<span id="cb131-6"><a href="#cb131-6" aria-hidden="true" tabindex="-1"></a>km.out5<span class="sc">$</span>tot.withinss</span>
<span id="cb131-7"><a href="#cb131-7" aria-hidden="true" tabindex="-1"></a>km.out5<span class="sc">$</span>totss</span>
<span id="cb131-8"><a href="#cb131-8" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(km.out5<span class="sc">$</span>cluster,iris.labs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We can compare the results with the model without variable standardization.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb132"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a>wss<span class="ot">=</span>km.out5<span class="sc">$</span>totss</span>
<span id="cb132-2"><a href="#cb132-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb132-3"><a href="#cb132-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span><span class="dv">10</span>)</span>
<span id="cb132-4"><a href="#cb132-4" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb132-5"><a href="#cb132-5" aria-hidden="true" tabindex="-1"></a>  wss[i] <span class="ot">=</span> <span class="fu">sum</span>(<span class="fu">kmeans</span>(iris.data2,<span class="at">centers=</span>i)<span class="sc">$</span>withinss)</span>
<span id="cb132-6"><a href="#cb132-6" aria-hidden="true" tabindex="-1"></a>} </span>
<span id="cb132-7"><a href="#cb132-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb132-8"><a href="#cb132-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb132-9"><a href="#cb132-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>, wss, </span>
<span id="cb132-10"><a href="#cb132-10" aria-hidden="true" tabindex="-1"></a>     <span class="at">type=</span><span class="st">"b"</span>, </span>
<span id="cb132-11"><a href="#cb132-11" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">"Number of Clusters"</span>, </span>
<span id="cb132-12"><a href="#cb132-12" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">"Within groups sum of squares"</span>, </span>
<span id="cb132-13"><a href="#cb132-13" aria-hidden="true" tabindex="-1"></a>     <span class="at">main=</span><span class="st">"find the optimal value of K"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Once again, do we get the clustering results as the previous two models? Doe the total within-cluster sum of squares change? Does the total sum of squares change? We use <code>K=3</code> in this case because of our prior knowledge. Now let’s use <code>km.out5</code> to check if <code>K=3</code> is an optimal choice (you can also check it using other models). We calculate the total within-cluster sum of squares from <code>K=1</code> to <code>K=10</code>. Based on the plot, <code>K=3</code> is a good choice.</p>
<!-- -->

</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb133" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb133-2"><a href="#cb133-2" aria-hidden="true" tabindex="-1"></a><span class="an">project:</span></span>
<span id="cb133-3"><a href="#cb133-3" aria-hidden="true" tabindex="-1"></a><span class="co">  type: website</span></span>
<span id="cb133-4"><a href="#cb133-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-5"><a href="#cb133-5" aria-hidden="true" tabindex="-1"></a><span class="an">website:</span></span>
<span id="cb133-6"><a href="#cb133-6" aria-hidden="true" tabindex="-1"></a><span class="co">  title: "CIS9660 Lab Compilation"</span></span>
<span id="cb133-7"><a href="#cb133-7" aria-hidden="true" tabindex="-1"></a><span class="co">  author: "Chris Panlasigui, Yuanfeng Cai"</span></span>
<span id="cb133-8"><a href="#cb133-8" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span><span class="co"> </span></span>
<span id="cb133-9"><a href="#cb133-9" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb133-10"><a href="#cb133-10" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true</span></span>
<span id="cb133-11"><a href="#cb133-11" aria-hidden="true" tabindex="-1"></a><span class="co">    code-block-border-left: "#31BAE9"</span></span>
<span id="cb133-12"><a href="#cb133-12" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb133-13"><a href="#cb133-13" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-depth: 3</span></span>
<span id="cb133-14"><a href="#cb133-14" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-title: Contents</span></span>
<span id="cb133-15"><a href="#cb133-15" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: show</span></span>
<span id="cb133-16"><a href="#cb133-16" aria-hidden="true" tabindex="-1"></a><span class="co">    code-summary: "Code"</span></span>
<span id="cb133-17"><a href="#cb133-17" aria-hidden="true" tabindex="-1"></a><span class="co">    code-overflow: wrap </span></span>
<span id="cb133-18"><a href="#cb133-18" aria-hidden="true" tabindex="-1"></a><span class="an">editor:</span><span class="co"> visual</span></span>
<span id="cb133-19"><a href="#cb133-19" aria-hidden="true" tabindex="-1"></a><span class="an">execute:</span></span>
<span id="cb133-20"><a href="#cb133-20" aria-hidden="true" tabindex="-1"></a><span class="co">  output: false</span></span>
<span id="cb133-21"><a href="#cb133-21" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb133-22"><a href="#cb133-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-23"><a href="#cb133-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-24"><a href="#cb133-24" aria-hidden="true" tabindex="-1"></a><span class="fu"># Exploratory Data Analysis {#sec-1eda}</span></span>
<span id="cb133-25"><a href="#cb133-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-26"><a href="#cb133-26" aria-hidden="true" tabindex="-1"></a><span class="fu">## Loading Data {#sec-loaddata}</span></span>
<span id="cb133-27"><a href="#cb133-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-28"><a href="#cb133-28" aria-hidden="true" tabindex="-1"></a>Before the lab, please download and save data <span class="in">`AutoLab1.csv`</span> from Blackboard-Data.</span>
<span id="cb133-29"><a href="#cb133-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-32"><a href="#cb133-32" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-33"><a href="#cb133-33" aria-hidden="true" tabindex="-1"></a><span class="co"># use file.choose() if you want a window to open for you to locate your file</span></span>
<span id="cb133-34"><a href="#cb133-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Auto=read.csv(file.choose(),header=T, stringsAsFactors=TRUE)</span></span>
<span id="cb133-35"><a href="#cb133-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-36"><a href="#cb133-36" aria-hidden="true" tabindex="-1"></a><span class="co"># if you know the path to your file you can directly include it and omit file.choose()</span></span>
<span id="cb133-37"><a href="#cb133-37" aria-hidden="true" tabindex="-1"></a>Auto<span class="ot">=</span><span class="fu">read.csv</span>(<span class="at">file=</span><span class="st">"../raw_data/autolab1.csv"</span>,</span>
<span id="cb133-38"><a href="#cb133-38" aria-hidden="true" tabindex="-1"></a>              <span class="at">header=</span>T, </span>
<span id="cb133-39"><a href="#cb133-39" aria-hidden="true" tabindex="-1"></a>              <span class="at">stringsAsFactors=</span><span class="cn">TRUE</span>)</span>
<span id="cb133-40"><a href="#cb133-40" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-41"><a href="#cb133-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-42"><a href="#cb133-42" aria-hidden="true" tabindex="-1"></a>You can use function <span class="in">`read.table()`</span> or <span class="in">`read.csv()`</span> to import data into R, depending on the file type. You can use <span class="in">`help(read.csv)`</span> or <span class="in">`?read.csv`</span> to find more about how to use this function. Since the file type is .csv, we use <span class="in">`read.csv()`</span>in this case. Use the following command to load <span class="in">`AutoLab1.csv`</span> into R and store it as an object called Auto.</span>
<span id="cb133-43"><a href="#cb133-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-44"><a href="#cb133-44" aria-hidden="true" tabindex="-1"></a>The command, <span class="in">`file.choose()`</span> locates the file from your local drive, the option <span class="in">`header=T`</span> (or <span class="in">`header=TRUE`</span>) means that the first line of the file contains the variable names, the option <span class="in">`stringsAsFactors=TRUE`</span> (or <span class="in">`stringsAsFactors=T`</span>) means that converting characters to factors</span>
<span id="cb133-45"><a href="#cb133-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-46"><a href="#cb133-46" aria-hidden="true" tabindex="-1"></a><span class="fu">## Data Structure {#sec-1datastruct}</span></span>
<span id="cb133-47"><a href="#cb133-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-50"><a href="#cb133-50" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-51"><a href="#cb133-51" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Auto)</span>
<span id="cb133-52"><a href="#cb133-52" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(Auto)</span>
<span id="cb133-53"><a href="#cb133-53" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(Auto)</span>
<span id="cb133-54"><a href="#cb133-54" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-55"><a href="#cb133-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-56"><a href="#cb133-56" aria-hidden="true" tabindex="-1"></a>You can use <span class="in">`head()`</span> to look at the first 6 rows. Function <span class="in">`dim()`</span> can output the number of rows followed by the number of columns and function <span class="in">`str()`</span> can return the data structure.</span>
<span id="cb133-57"><a href="#cb133-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-58"><a href="#cb133-58" aria-hidden="true" tabindex="-1"></a><span class="fu">## Summary Statistics {#sec-1summarystat}</span></span>
<span id="cb133-59"><a href="#cb133-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-62"><a href="#cb133-62" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-63"><a href="#cb133-63" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(Auto)</span>
<span id="cb133-64"><a href="#cb133-64" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-65"><a href="#cb133-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-66"><a href="#cb133-66" aria-hidden="true" tabindex="-1"></a>We can use function <span class="in">`summary()`</span> to output the summary statistics of data.</span>
<span id="cb133-67"><a href="#cb133-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-68"><a href="#cb133-68" aria-hidden="true" tabindex="-1"></a><span class="fu">## Data Restructuring {#sec-1datarestruct}</span></span>
<span id="cb133-69"><a href="#cb133-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-72"><a href="#cb133-72" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-73"><a href="#cb133-73" aria-hidden="true" tabindex="-1"></a>Auto[,<span class="dv">2</span>]<span class="ot">=</span><span class="fu">as.factor</span>(Auto[,<span class="dv">2</span>])</span>
<span id="cb133-74"><a href="#cb133-74" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(Auto[,<span class="dv">2</span>])</span>
<span id="cb133-75"><a href="#cb133-75" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-76"><a href="#cb133-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-77"><a href="#cb133-77" aria-hidden="true" tabindex="-1"></a>The variable cylinders (i.e. the second column) is stored as a quantitative variable. As it only has a small number of possible values, we can convert it to a qualitative variable. Function as.factor() converts a quantitative variable into a qualitative variable. Check the summary statistics of cylinders to see if it is the same as the output in @sec-1summarystat.</span>
<span id="cb133-78"><a href="#cb133-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-79"><a href="#cb133-79" aria-hidden="true" tabindex="-1"></a><span class="fu">## Graphs {#sec-1edagraphs}</span></span>
<span id="cb133-80"><a href="#cb133-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-81"><a href="#cb133-81" aria-hidden="true" tabindex="-1"></a><span class="fu">### Scatterplot {#sec-1edascatter}</span></span>
<span id="cb133-82"><a href="#cb133-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-85"><a href="#cb133-85" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-86"><a href="#cb133-86" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span>Auto<span class="sc">$</span>horsepower, <span class="at">y=</span>Auto<span class="sc">$</span>mpg)</span>
<span id="cb133-87"><a href="#cb133-87" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-88"><a href="#cb133-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-89"><a href="#cb133-89" aria-hidden="true" tabindex="-1"></a>We can use function plot() to produce plots. However, simply typing the variable names does not work, because R does not know where to find those variables. You can either use the <span class="in">`$`</span>sign or </span>
<span id="cb133-90"><a href="#cb133-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-93"><a href="#cb133-93" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-94"><a href="#cb133-94" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(Auto)</span>
<span id="cb133-95"><a href="#cb133-95" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(Auto)</span>
<span id="cb133-96"><a href="#cb133-96" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span>horsepower , </span>
<span id="cb133-97"><a href="#cb133-97" aria-hidden="true" tabindex="-1"></a>     <span class="at">y=</span>mpg, <span class="at">col =</span><span class="st">"red"</span>, </span>
<span id="cb133-98"><a href="#cb133-98" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">"Horsepower"</span>,</span>
<span id="cb133-99"><a href="#cb133-99" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span><span class="st">"MPG "</span>,</span>
<span id="cb133-100"><a href="#cb133-100" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">30</span>,<span class="dv">250</span>), </span>
<span id="cb133-101"><a href="#cb133-101" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">50</span>), </span>
<span id="cb133-102"><a href="#cb133-102" aria-hidden="true" tabindex="-1"></a>     <span class="at">main=</span><span class="st">"Horsepower vs. MPG"</span>)</span>
<span id="cb133-103"><a href="#cb133-103" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-104"><a href="#cb133-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-105"><a href="#cb133-105" aria-hidden="true" tabindex="-1"></a>Use function <span class="in">`attach()`</span> to tell R to make the variables available by name. Function <span class="in">`names()`</span> lists all variable names. Then you can use the variable name directly.</span>
<span id="cb133-106"><a href="#cb133-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-107"><a href="#cb133-107" aria-hidden="true" tabindex="-1"></a>Here the option <span class="in">`col ="red"`</span> tells R that color data points red. The options <span class="in">`xlab="Horsepower",ylab ="MPG"`</span>, and <span class="in">`main="Horsepower vs. MPG"`</span> tell R the x axis title, the y axis title and the main title respectively.</span>
<span id="cb133-108"><a href="#cb133-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-109"><a href="#cb133-109" aria-hidden="true" tabindex="-1"></a>The options <span class="in">`xlim`</span> and <span class="in">`ylim`</span> tell R the range of x axis and y axis.</span>
<span id="cb133-110"><a href="#cb133-110" aria-hidden="true" tabindex="-1"></a>There are many other optional parameters in function <span class="in">`plot()`</span>, which we do not include in this case. You can use <span class="in">`help(plot)`</span> or <span class="in">`?plot`</span> to explore more about them.</span>
<span id="cb133-111"><a href="#cb133-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-114"><a href="#cb133-114" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-115"><a href="#cb133-115" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb133-116"><a href="#cb133-116" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span>acceleration ,</span>
<span id="cb133-117"><a href="#cb133-117" aria-hidden="true" tabindex="-1"></a>     <span class="at">y=</span>mpg, </span>
<span id="cb133-118"><a href="#cb133-118" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span><span class="st">"red"</span>, </span>
<span id="cb133-119"><a href="#cb133-119" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">"Acceleration"</span>,</span>
<span id="cb133-120"><a href="#cb133-120" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span><span class="st">"MPG "</span>, </span>
<span id="cb133-121"><a href="#cb133-121" aria-hidden="true" tabindex="-1"></a>     <span class="at">main=</span><span class="st">"Acceleration vs. MPG"</span>)</span>
<span id="cb133-122"><a href="#cb133-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-123"><a href="#cb133-123" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span>weight , </span>
<span id="cb133-124"><a href="#cb133-124" aria-hidden="true" tabindex="-1"></a>     <span class="at">y=</span>mpg, </span>
<span id="cb133-125"><a href="#cb133-125" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span><span class="st">"red"</span>, </span>
<span id="cb133-126"><a href="#cb133-126" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">"Weight"</span>, </span>
<span id="cb133-127"><a href="#cb133-127" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span><span class="st">"MPG "</span>, </span>
<span id="cb133-128"><a href="#cb133-128" aria-hidden="true" tabindex="-1"></a>     <span class="at">main=</span><span class="st">"Weight vs. MPG"</span>)</span>
<span id="cb133-129"><a href="#cb133-129" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-130"><a href="#cb133-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-131"><a href="#cb133-131" aria-hidden="true" tabindex="-1"></a>We can use function <span class="in">`par(mfrow=c(nrows,ncols))`</span> to combine multiple plots into one graph. For example, <span class="in">`par(mfrow=c(3,1))`</span> indicates that three figures will be arranged in 3 rows and 1 column. Now let’s generate another two figures and arrange them in one column.</span>
<span id="cb133-132"><a href="#cb133-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-135"><a href="#cb133-135" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-136"><a href="#cb133-136" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(Auto)</span>
<span id="cb133-137"><a href="#cb133-137" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(Auto[<span class="fu">c</span>(<span class="dv">3</span><span class="sc">:</span><span class="dv">5</span>)])</span>
<span id="cb133-138"><a href="#cb133-138" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-139"><a href="#cb133-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-140"><a href="#cb133-140" aria-hidden="true" tabindex="-1"></a>The <span class="in">`pairs()`</span> function creates a scatterplot for every scatterplot pair of variables. We can also produce scatterplots matrix for just a subset of the variables.</span>
<span id="cb133-141"><a href="#cb133-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-142"><a href="#cb133-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-143"><a href="#cb133-143" aria-hidden="true" tabindex="-1"></a><span class="fu">### Barplot {#sec-edabarplot}</span></span>
<span id="cb133-144"><a href="#cb133-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-147"><a href="#cb133-147" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-148"><a href="#cb133-148" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb133-149"><a href="#cb133-149" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span>cylinders, </span>
<span id="cb133-150"><a href="#cb133-150" aria-hidden="true" tabindex="-1"></a>    <span class="at">y=</span>mpg, </span>
<span id="cb133-151"><a href="#cb133-151" aria-hidden="true" tabindex="-1"></a>    <span class="at">col=</span><span class="st">"red"</span>, </span>
<span id="cb133-152"><a href="#cb133-152" aria-hidden="true" tabindex="-1"></a>    <span class="at">varwidth=</span><span class="cn">TRUE</span>, </span>
<span id="cb133-153"><a href="#cb133-153" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">" Cylinders "</span>, </span>
<span id="cb133-154"><a href="#cb133-154" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylab=</span><span class="st">"MPG "</span>, </span>
<span id="cb133-155"><a href="#cb133-155" aria-hidden="true" tabindex="-1"></a>    <span class="at">main=</span><span class="st">"Cylinders vs. MPG"</span>)</span>
<span id="cb133-156"><a href="#cb133-156" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-157"><a href="#cb133-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-158"><a href="#cb133-158" aria-hidden="true" tabindex="-1"></a>If the variable plotted on the x-axis is categorical, then boxplots will automatically be produced.</span>
<span id="cb133-159"><a href="#cb133-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-160"><a href="#cb133-160" aria-hidden="true" tabindex="-1"></a><span class="fu">### Histogram {#sec-edahist}</span></span>
<span id="cb133-161"><a href="#cb133-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-164"><a href="#cb133-164" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-165"><a href="#cb133-165" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(<span class="at">x=</span>mpg, </span>
<span id="cb133-166"><a href="#cb133-166" aria-hidden="true" tabindex="-1"></a>     <span class="at">breaks=</span><span class="dv">10</span>, </span>
<span id="cb133-167"><a href="#cb133-167" aria-hidden="true" tabindex="-1"></a>     <span class="at">col=</span><span class="st">"red"</span>, </span>
<span id="cb133-168"><a href="#cb133-168" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">"MPG "</span>,</span>
<span id="cb133-169"><a href="#cb133-169" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">50</span>),</span>
<span id="cb133-170"><a href="#cb133-170" aria-hidden="true" tabindex="-1"></a>     <span class="at">main=</span><span class="st">"Histogram of MPG"</span>)</span>
<span id="cb133-171"><a href="#cb133-171" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-172"><a href="#cb133-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-173"><a href="#cb133-173" aria-hidden="true" tabindex="-1"></a>We can use <span class="in">`hist()`</span> function to plot a histogram. The option <span class="in">`“breaks=10”`</span> sets the total number of bins.</span>
<span id="cb133-174"><a href="#cb133-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-175"><a href="#cb133-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-176"><a href="#cb133-176" aria-hidden="true" tabindex="-1"></a><span class="fu"># Linear Regression {#sec-2linearregression}</span></span>
<span id="cb133-177"><a href="#cb133-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-178"><a href="#cb133-178" aria-hidden="true" tabindex="-1"></a><span class="fu">## Load Data {#sec-2loaddata}</span></span>
<span id="cb133-179"><a href="#cb133-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-180"><a href="#cb133-180" aria-hidden="true" tabindex="-1"></a>Before the lab, please download Data Lab2Data.csv from Blackboard→Data. Then load Data Lab2Data.csv to object Datlab2.</span>
<span id="cb133-181"><a href="#cb133-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-184"><a href="#cb133-184" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-185"><a href="#cb133-185" aria-hidden="true" tabindex="-1"></a><span class="co"># delete global environment</span></span>
<span id="cb133-186"><a href="#cb133-186" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>())</span>
<span id="cb133-187"><a href="#cb133-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-188"><a href="#cb133-188" aria-hidden="true" tabindex="-1"></a><span class="co"># load data</span></span>
<span id="cb133-189"><a href="#cb133-189" aria-hidden="true" tabindex="-1"></a>Datlab2 <span class="ot">=</span> <span class="fu">read.csv</span>(<span class="at">file=</span><span class="st">"../raw_data/Lab2Data.csv"</span>, </span>
<span id="cb133-190"><a href="#cb133-190" aria-hidden="true" tabindex="-1"></a>                   <span class="at">header=</span>T, </span>
<span id="cb133-191"><a href="#cb133-191" aria-hidden="true" tabindex="-1"></a>                   <span class="at">stringsAsFactors=</span><span class="cn">TRUE</span>)</span>
<span id="cb133-192"><a href="#cb133-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-193"><a href="#cb133-193" aria-hidden="true" tabindex="-1"></a><span class="co"># check column/variable names</span></span>
<span id="cb133-194"><a href="#cb133-194" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(Datlab2)</span>
<span id="cb133-195"><a href="#cb133-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-196"><a href="#cb133-196" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(Datlab2)</span>
<span id="cb133-197"><a href="#cb133-197" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-198"><a href="#cb133-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-199"><a href="#cb133-199" aria-hidden="true" tabindex="-1"></a>There are four input variables $(𝑥_1 ...𝑥_4)$ and one response variable $y$ in this data. Variable $x_4$ is a categorical variable with two possible values. We should create a dummy variable that takes on two possible numerical values. </span>
<span id="cb133-200"><a href="#cb133-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-203"><a href="#cb133-203" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-204"><a href="#cb133-204" aria-hidden="true" tabindex="-1"></a><span class="fu">contrasts</span>(x4)</span>
<span id="cb133-205"><a href="#cb133-205" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-206"><a href="#cb133-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-207"><a href="#cb133-207" aria-hidden="true" tabindex="-1"></a>The <span class="in">`contrasts()`</span> function returns how R codes this dummy variable.</span>
<span id="cb133-208"><a href="#cb133-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-209"><a href="#cb133-209" aria-hidden="true" tabindex="-1"></a><span class="fu">## Build Model {#sec-2buildmodel}</span></span>
<span id="cb133-210"><a href="#cb133-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-211"><a href="#cb133-211" aria-hidden="true" tabindex="-1"></a><span class="fu">### Full Model {#sec-2fullmodel}</span></span>
<span id="cb133-212"><a href="#cb133-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-215"><a href="#cb133-215" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-216"><a href="#cb133-216" aria-hidden="true" tabindex="-1"></a>Model1<span class="ot">=</span><span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4,<span class="at">data=</span> Datlab2)</span>
<span id="cb133-217"><a href="#cb133-217" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-218"><a href="#cb133-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-219"><a href="#cb133-219" aria-hidden="true" tabindex="-1"></a>We first fit the entire data with all input variables into a multiple linear regression model Model1. We can use the <span class="in">`lm()`</span> function:</span>
<span id="cb133-220"><a href="#cb133-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-221"><a href="#cb133-221" aria-hidden="true" tabindex="-1"></a>$$ y =\beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_4 + \epsilon$$ {#eq-linearm1}</span>
<span id="cb133-222"><a href="#cb133-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-225"><a href="#cb133-225" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-226"><a href="#cb133-226" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(Model1)</span>
<span id="cb133-227"><a href="#cb133-227" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-228"><a href="#cb133-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-229"><a href="#cb133-229" aria-hidden="true" tabindex="-1"></a>We can use the function <span class="in">`summary()`</span> to obtain the coefficients, their associated <span class="in">`p-values`</span>, and the $R^2$. We can find that only one variable looks insignificant in this model.</span>
<span id="cb133-230"><a href="#cb133-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-231"><a href="#cb133-231" aria-hidden="true" tabindex="-1"></a><span class="fu">### Model with interaction effect {#sec-2interactioneffect}</span></span>
<span id="cb133-232"><a href="#cb133-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-235"><a href="#cb133-235" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-236"><a href="#cb133-236" aria-hidden="true" tabindex="-1"></a>Model2<span class="ot">=</span><span class="fu">lm</span>(y<span class="sc">~</span>x3<span class="sc">*</span>x4)</span>
<span id="cb133-237"><a href="#cb133-237" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(Model2)</span>
<span id="cb133-238"><a href="#cb133-238" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-239"><a href="#cb133-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-240"><a href="#cb133-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-241"><a href="#cb133-241" aria-hidden="true" tabindex="-1"></a>We can also check if the model should include an interaction effect. For example, to test an interaction effect between $x_3$ and $x_4$, we can include <span class="in">`lm(y~x3*x4)`</span>. The syntax <span class="in">`x3*x4`</span> in the function <span class="in">`lm()`</span> simultaneously includes $x_3$, $x_4$, and $x_3 \times x_4$𝑥4. That is, <span class="in">`lm(y~x3*x4)`</span> fits the following model:</span>
<span id="cb133-242"><a href="#cb133-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-243"><a href="#cb133-243" aria-hidden="true" tabindex="-1"></a>$$y = \beta_0 + \beta_1 x_3 + \beta_2 x_4 + \beta_3(x_3 \times x_4) + \epsilon$$ {#eq-linearm2}</span>
<span id="cb133-244"><a href="#cb133-244" aria-hidden="true" tabindex="-1"></a>The result suggests that the interaction effect is significant.</span>
<span id="cb133-245"><a href="#cb133-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-248"><a href="#cb133-248" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-249"><a href="#cb133-249" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span><span class="fu">predict</span>(Model2), <span class="at">y=</span><span class="fu">residuals</span>(Model2))</span>
<span id="cb133-250"><a href="#cb133-250" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span><span class="fu">predict</span>(Model2), <span class="at">y=</span><span class="fu">rstudent</span>(Model2))</span>
<span id="cb133-251"><a href="#cb133-251" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-252"><a href="#cb133-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-253"><a href="#cb133-253" aria-hidden="true" tabindex="-1"></a>We can generate diagnostic plots for models. The function <span class="in">`rstudent()`</span> returns the studentized residuals, which can be used to identity outliers. Given the diagnostics results, there is no outlier in <span class="in">`Model2`</span>.</span>
<span id="cb133-254"><a href="#cb133-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-255"><a href="#cb133-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-256"><a href="#cb133-256" aria-hidden="true" tabindex="-1"></a><span class="fu">## Resampling Methods {#sec-2resampling}</span></span>
<span id="cb133-257"><a href="#cb133-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-258"><a href="#cb133-258" aria-hidden="true" tabindex="-1"></a>Now we try two candidate models <span class="in">`M1`</span> and <span class="in">`M2`</span>.  We will use re-sampling methods to compare their performance. </span>
<span id="cb133-259"><a href="#cb133-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-260"><a href="#cb133-260" aria-hidden="true" tabindex="-1"></a>$$M1: y =\beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_4 + \beta_5(x_3 \times x_4) +  \epsilon$$ {#eq-M1}</span>
<span id="cb133-261"><a href="#cb133-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-262"><a href="#cb133-262" aria-hidden="true" tabindex="-1"></a>$$M2: y = \beta_0 + \beta_1 x_3 + \beta_2 x_4 + \beta_3(x_3 \times x_4) + \epsilon$$ {#eq-M2}</span>
<span id="cb133-263"><a href="#cb133-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-264"><a href="#cb133-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-265"><a href="#cb133-265" aria-hidden="true" tabindex="-1"></a><span class="fu">### Hold-out {#sec-2holdout}</span></span>
<span id="cb133-266"><a href="#cb133-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-267"><a href="#cb133-267" aria-hidden="true" tabindex="-1"></a>We use two types of re-sampling methods. First, we illustrate how to compare the models using hold-out. We use 80-20 hold-out in this case.  We develop models using a training data set and assess the model performance using a test data set. </span>
<span id="cb133-268"><a href="#cb133-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-271"><a href="#cb133-271" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-272"><a href="#cb133-272" aria-hidden="true" tabindex="-1"></a><span class="co"># reproduceable random sampling</span></span>
<span id="cb133-273"><a href="#cb133-273" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb133-274"><a href="#cb133-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-275"><a href="#cb133-275" aria-hidden="true" tabindex="-1"></a><span class="co">#index for training data set</span></span>
<span id="cb133-276"><a href="#cb133-276" aria-hidden="true" tabindex="-1"></a>train<span class="ot">=</span><span class="fu">sample</span>(<span class="fu">nrow</span>(Datlab2),<span class="fu">nrow</span>(Datlab2)<span class="sc">*</span><span class="fl">0.8</span>) </span>
<span id="cb133-277"><a href="#cb133-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-278"><a href="#cb133-278" aria-hidden="true" tabindex="-1"></a><span class="co">#training data set</span></span>
<span id="cb133-279"><a href="#cb133-279" aria-hidden="true" tabindex="-1"></a>Datlab2.train<span class="ot">=</span>Datlab2[train, ] </span>
<span id="cb133-280"><a href="#cb133-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-281"><a href="#cb133-281" aria-hidden="true" tabindex="-1"></a><span class="co">#test data set</span></span>
<span id="cb133-282"><a href="#cb133-282" aria-hidden="true" tabindex="-1"></a>Datlab2.test<span class="ot">=</span>Datlab2[<span class="sc">-</span>train, ] </span>
<span id="cb133-283"><a href="#cb133-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-284"><a href="#cb133-284" aria-hidden="true" tabindex="-1"></a><span class="co">#the response vector in the test set</span></span>
<span id="cb133-285"><a href="#cb133-285" aria-hidden="true" tabindex="-1"></a>y.test<span class="ot">=</span>y[<span class="sc">-</span>train] </span>
<span id="cb133-286"><a href="#cb133-286" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-287"><a href="#cb133-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-288"><a href="#cb133-288" aria-hidden="true" tabindex="-1"></a>We first use the <span class="in">`sample()`</span> function to randomly split the original data set into one training set and one test set.</span>
<span id="cb133-289"><a href="#cb133-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-290"><a href="#cb133-290" aria-hidden="true" tabindex="-1"></a>The function <span class="in">`nrow()`</span> counts the total number of rows in <span class="in">`Datlab2`</span>. Sometimes we want to reproduce the exact same sampling results; we can use the <span class="in">`set.seed()`</span> function. To use this function, you need to set a seed, which is an arbitrary integer, e.g. 1.</span>
<span id="cb133-291"><a href="#cb133-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-294"><a href="#cb133-294" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-295"><a href="#cb133-295" aria-hidden="true" tabindex="-1"></a><span class="co"># full model with train data</span></span>
<span id="cb133-296"><a href="#cb133-296" aria-hidden="true" tabindex="-1"></a>M1train<span class="ot">=</span><span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">*</span>x4, <span class="at">data=</span>Datlab2.train)</span>
<span id="cb133-297"><a href="#cb133-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-298"><a href="#cb133-298" aria-hidden="true" tabindex="-1"></a><span class="co"># interaction model with train data</span></span>
<span id="cb133-299"><a href="#cb133-299" aria-hidden="true" tabindex="-1"></a>M2train <span class="ot">=</span><span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x3<span class="sc">*</span>x4, <span class="at">data=</span>Datlab2.train)</span>
<span id="cb133-300"><a href="#cb133-300" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-301"><a href="#cb133-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-302"><a href="#cb133-302" aria-hidden="true" tabindex="-1"></a>The first model of choice <span class="in">`M1`</span> contains all four variables and one interaction term. The second model <span class="in">`M2`</span> contains three input variables and one interaction term. We learn the two models only using the training data set.</span>
<span id="cb133-303"><a href="#cb133-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-306"><a href="#cb133-306" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-307"><a href="#cb133-307" aria-hidden="true" tabindex="-1"></a><span class="co"># test performance of full model</span></span>
<span id="cb133-308"><a href="#cb133-308" aria-hidden="true" tabindex="-1"></a>y.predictM1<span class="ot">=</span><span class="fu">predict</span>(M1train,Datlab2.test)</span>
<span id="cb133-309"><a href="#cb133-309" aria-hidden="true" tabindex="-1"></a><span class="co"># performance measure using MSE of full model</span></span>
<span id="cb133-310"><a href="#cb133-310" aria-hidden="true" tabindex="-1"></a>M1MSE<span class="ot">=</span><span class="fu">mean</span>((y.test<span class="sc">-</span>y.predictM1)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb133-311"><a href="#cb133-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-312"><a href="#cb133-312" aria-hidden="true" tabindex="-1"></a><span class="co"># test performance of interaction model</span></span>
<span id="cb133-313"><a href="#cb133-313" aria-hidden="true" tabindex="-1"></a>y.predictM2<span class="ot">=</span><span class="fu">predict</span>(M2train,Datlab2.test)</span>
<span id="cb133-314"><a href="#cb133-314" aria-hidden="true" tabindex="-1"></a><span class="co"># performance measure using MSE of interaction model</span></span>
<span id="cb133-315"><a href="#cb133-315" aria-hidden="true" tabindex="-1"></a>M2MSE<span class="ot">=</span><span class="fu">mean</span>((y.test<span class="sc">-</span>y.predictM2)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb133-316"><a href="#cb133-316" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-317"><a href="#cb133-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-318"><a href="#cb133-318" aria-hidden="true" tabindex="-1"></a>To compare the model performance, we calculate the MSE of each model using the testing data set. The function <span class="in">`predict()`</span> predicts the value of the response variable for each observation in test data. <span class="in">`y.predictM1`</span> stores the predicted value of each observation in the test data set using model <span class="in">`M1`</span>, and <span class="in">`y.predictM2`</span> stores the predicted value of each observation in the test data set using model <span class="in">`M2`</span>. The <span class="in">`mean()`</span> function here is to calculate the average prediction deviation, i.e. MSE, in the entire test data.</span>
<span id="cb133-319"><a href="#cb133-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-320"><a href="#cb133-320" aria-hidden="true" tabindex="-1"></a><span class="fu">#### AIC, BIC, Adjusted $R^2$ </span></span>
<span id="cb133-321"><a href="#cb133-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-322"><a href="#cb133-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-325"><a href="#cb133-325" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-326"><a href="#cb133-326" aria-hidden="true" tabindex="-1"></a><span class="co"># other performance measure of full model</span></span>
<span id="cb133-327"><a href="#cb133-327" aria-hidden="true" tabindex="-1"></a><span class="fu">AIC</span>(M1train) <span class="co"># AIC</span></span>
<span id="cb133-328"><a href="#cb133-328" aria-hidden="true" tabindex="-1"></a><span class="fu">BIC</span>(M1train) <span class="co"># BIC</span></span>
<span id="cb133-329"><a href="#cb133-329" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(M1train) <span class="co">#adj R2</span></span>
<span id="cb133-330"><a href="#cb133-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-331"><a href="#cb133-331" aria-hidden="true" tabindex="-1"></a><span class="co"># other performance measure of interaction model</span></span>
<span id="cb133-332"><a href="#cb133-332" aria-hidden="true" tabindex="-1"></a><span class="fu">AIC</span>(M2train) <span class="co"># AIC</span></span>
<span id="cb133-333"><a href="#cb133-333" aria-hidden="true" tabindex="-1"></a><span class="fu">BIC</span>(M2train) <span class="co"># BIC </span></span>
<span id="cb133-334"><a href="#cb133-334" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(M2train) <span class="co"># adj. R2</span></span>
<span id="cb133-335"><a href="#cb133-335" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-336"><a href="#cb133-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-337"><a href="#cb133-337" aria-hidden="true" tabindex="-1"></a>In addition to using MSE, the model can be assessed using functions <span class="in">`BIC()`</span>, <span class="in">`AIC()`</span> and adjusted R2 in <span class="in">`summary()`</span>.</span>
<span id="cb133-338"><a href="#cb133-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-339"><a href="#cb133-339" aria-hidden="true" tabindex="-1"></a><span class="fu">### Cross-Validation (CV)</span></span>
<span id="cb133-340"><a href="#cb133-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-341"><a href="#cb133-341" aria-hidden="true" tabindex="-1"></a>Now we illustrate how to compare the models using cross-validation. We use 5-fold cross validation along with MSE in this case. </span>
<span id="cb133-342"><a href="#cb133-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-345"><a href="#cb133-345" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-346"><a href="#cb133-346" aria-hidden="true" tabindex="-1"></a><span class="co"># reproduceable random sampling</span></span>
<span id="cb133-347"><a href="#cb133-347" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>) </span>
<span id="cb133-348"><a href="#cb133-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-349"><a href="#cb133-349" aria-hidden="true" tabindex="-1"></a><span class="co"># number of folds</span></span>
<span id="cb133-350"><a href="#cb133-350" aria-hidden="true" tabindex="-1"></a>k<span class="ot">=</span><span class="dv">5</span></span>
<span id="cb133-351"><a href="#cb133-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-352"><a href="#cb133-352" aria-hidden="true" tabindex="-1"></a><span class="co"># empty container to hold MSE of full model using CV</span></span>
<span id="cb133-353"><a href="#cb133-353" aria-hidden="true" tabindex="-1"></a>M1CVMSE<span class="ot">=</span><span class="fu">rep</span>(<span class="dv">0</span>,k)</span>
<span id="cb133-354"><a href="#cb133-354" aria-hidden="true" tabindex="-1"></a><span class="co"># emtpy container to hold MSE of interaction model using CV</span></span>
<span id="cb133-355"><a href="#cb133-355" aria-hidden="true" tabindex="-1"></a>M2CVMSE<span class="ot">=</span><span class="fu">rep</span>(<span class="dv">0</span>,k)</span>
<span id="cb133-356"><a href="#cb133-356" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-357"><a href="#cb133-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-358"><a href="#cb133-358" aria-hidden="true" tabindex="-1"></a>We first create a vector to store the accuracy results associated with each fold for each model. We set the initial values for this vector as zero.</span>
<span id="cb133-359"><a href="#cb133-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-362"><a href="#cb133-362" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-363"><a href="#cb133-363" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb133-364"><a href="#cb133-364" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: true</span></span>
<span id="cb133-365"><a href="#cb133-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-366"><a href="#cb133-366" aria-hidden="true" tabindex="-1"></a><span class="co"># split data into k=5 folds </span></span>
<span id="cb133-367"><a href="#cb133-367" aria-hidden="true" tabindex="-1"></a>folds<span class="ot">=</span><span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>k,<span class="fu">nrow</span>(Datlab2),<span class="at">replace=</span><span class="cn">TRUE</span>)</span>
<span id="cb133-368"><a href="#cb133-368" aria-hidden="true" tabindex="-1"></a>folds</span>
<span id="cb133-369"><a href="#cb133-369" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-370"><a href="#cb133-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-371"><a href="#cb133-371" aria-hidden="true" tabindex="-1"></a>We use the <span class="in">`sample()`</span> function to split the original data set into five folds. This creates a vector of random values between 1 through 5.  This assigns the indices of <span class="in">`Datlab2`</span> to each fold.  </span>
<span id="cb133-372"><a href="#cb133-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-375"><a href="#cb133-375" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-376"><a href="#cb133-376" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>k) <span class="co"># iterate from 1 through k=5</span></span>
<span id="cb133-377"><a href="#cb133-377" aria-hidden="true" tabindex="-1"></a>{ </span>
<span id="cb133-378"><a href="#cb133-378" aria-hidden="true" tabindex="-1"></a>  <span class="co"># model of the train data portion of cv </span></span>
<span id="cb133-379"><a href="#cb133-379" aria-hidden="true" tabindex="-1"></a>  M1CV<span class="ot">=</span><span class="fu">lm</span>(y<span class="sc">~</span> x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">*</span>x4,<span class="at">data=</span>Datlab2[folds<span class="sc">!=</span>j,]) </span>
<span id="cb133-380"><a href="#cb133-380" aria-hidden="true" tabindex="-1"></a>  <span class="co"># obtain the performance (MSE) of the model M1CV by applying it to the test portion of cv  </span></span>
<span id="cb133-381"><a href="#cb133-381" aria-hidden="true" tabindex="-1"></a>  M1CVMSE[j]<span class="ot">=</span><span class="fu">mean</span>((y<span class="sc">-</span><span class="fu">predict</span>(M1CV,Datlab2))[folds<span class="sc">==</span>j]<span class="sc">^</span><span class="dv">2</span>) }</span>
<span id="cb133-382"><a href="#cb133-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-383"><a href="#cb133-383" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>k)</span>
<span id="cb133-384"><a href="#cb133-384" aria-hidden="true" tabindex="-1"></a>{ M2CV<span class="ot">=</span><span class="fu">lm</span>(y<span class="sc">~</span> x1 <span class="sc">+</span>x3<span class="sc">*</span>x4,<span class="at">data=</span>Datlab2[folds<span class="sc">!=</span>j,]) </span>
<span id="cb133-385"><a href="#cb133-385" aria-hidden="true" tabindex="-1"></a>M2CVMSE[j]<span class="ot">=</span><span class="fu">mean</span>((y<span class="sc">-</span><span class="fu">predict</span>(M2CV,Datlab2))[folds<span class="sc">==</span>j]<span class="sc">^</span><span class="dv">2</span>) }</span>
<span id="cb133-386"><a href="#cb133-386" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-387"><a href="#cb133-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-388"><a href="#cb133-388" aria-hidden="true" tabindex="-1"></a>During each iteration, the <span class="in">`Datlab2[folds!=j,]`</span> selects indices that are not equal to the $jth$ iteration and assigns it as the train data and stores the model value in <span class="in">`M1CV`</span>.  So during the first iteration, the data train data will be all the indices that are not assigned to 1 in the <span class="in">`folds`</span> vector. </span>
<span id="cb133-389"><a href="#cb133-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-390"><a href="#cb133-390" aria-hidden="true" tabindex="-1"></a><span class="in">`[folds==j]`</span> selects the indices that are equal to the $jth$ iteration, which is the test data.  So, <span class="in">`(y-predict(M1CV,Datlab2))[folds==j]^2`</span> is the standard error of the test data, which the difference between the actual values of <span class="in">`y`</span> to the predicted values based on the model <span class="in">`M1CV`</span>.  MSE is calculated by obtaining the mean of the standard error in each iteration and is stored in <span class="in">`M2CVMSE[j]`</span> where <span class="in">`j`</span> is the current iteration index. <span class="in">`M2CVMSE`</span> will then have 5 values since <span class="in">`j`</span> has been set from 1 through <span class="in">`k=5`</span>.</span>
<span id="cb133-391"><a href="#cb133-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-394"><a href="#cb133-394" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-395"><a href="#cb133-395" aria-hidden="true" tabindex="-1"></a>MeanM1MSE<span class="ot">=</span><span class="fu">mean</span>(M1CVMSE) <span class="do">###CVMSE-M1###</span></span>
<span id="cb133-396"><a href="#cb133-396" aria-hidden="true" tabindex="-1"></a>MeanM2MSE<span class="ot">=</span><span class="fu">mean</span>(M2CVMSE) <span class="do">###CVMSE-M2###</span></span>
<span id="cb133-397"><a href="#cb133-397" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-398"><a href="#cb133-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-399"><a href="#cb133-399" aria-hidden="true" tabindex="-1"></a>Finally, calculate the cross-validation MSE of <span class="in">`M1`</span> (@eq-M1) and <span class="in">`M2`</span> (@eq-M2) by obtaining the mean of each CV model. </span>
<span id="cb133-400"><a href="#cb133-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-401"><a href="#cb133-401" aria-hidden="true" tabindex="-1"></a><span class="fu"># Classification: Logistic Regression &amp; KNN {#sec-3class1}</span></span>
<span id="cb133-402"><a href="#cb133-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-403"><a href="#cb133-403" aria-hidden="true" tabindex="-1"></a><span class="fu">## Logistic Regression {#sec-3logistic}</span></span>
<span id="cb133-404"><a href="#cb133-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-407"><a href="#cb133-407" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-408"><a href="#cb133-408" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb133-409"><a href="#cb133-409" aria-hidden="true" tabindex="-1"></a><span class="co">#| </span></span>
<span id="cb133-410"><a href="#cb133-410" aria-hidden="true" tabindex="-1"></a><span class="co"># clear global env (remove all stored obj) </span></span>
<span id="cb133-411"><a href="#cb133-411" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>())</span>
<span id="cb133-412"><a href="#cb133-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-413"><a href="#cb133-413" aria-hidden="true" tabindex="-1"></a><span class="co"># load data</span></span>
<span id="cb133-414"><a href="#cb133-414" aria-hidden="true" tabindex="-1"></a>Default<span class="ot">=</span><span class="fu">read.csv</span>(<span class="at">file =</span> <span class="st">"../raw_data/Default.csv"</span>,</span>
<span id="cb133-415"><a href="#cb133-415" aria-hidden="true" tabindex="-1"></a>                 <span class="at">header=</span>T, <span class="at">stringsAsFactors=</span><span class="cn">TRUE</span>)</span>
<span id="cb133-416"><a href="#cb133-416" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(Default)</span>
<span id="cb133-417"><a href="#cb133-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-418"><a href="#cb133-418" aria-hidden="true" tabindex="-1"></a><span class="co"># check the dimensions</span></span>
<span id="cb133-419"><a href="#cb133-419" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(Default)</span>
<span id="cb133-420"><a href="#cb133-420" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(Default)</span>
<span id="cb133-421"><a href="#cb133-421" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-422"><a href="#cb133-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-423"><a href="#cb133-423" aria-hidden="true" tabindex="-1"></a>Load Data <span class="in">`Default.csv`</span> to object Default. The original data set contains 10000 observations.</span>
<span id="cb133-424"><a href="#cb133-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-427"><a href="#cb133-427" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-428"><a href="#cb133-428" aria-hidden="true" tabindex="-1"></a>glm.fit1<span class="ot">=</span><span class="fu">glm</span>(default<span class="sc">~</span>balance<span class="sc">+</span>income<span class="sc">+</span>student,</span>
<span id="cb133-429"><a href="#cb133-429" aria-hidden="true" tabindex="-1"></a>             <span class="at">family=</span><span class="st">"binomial"</span>,</span>
<span id="cb133-430"><a href="#cb133-430" aria-hidden="true" tabindex="-1"></a>             <span class="at">data=</span>Default)</span>
<span id="cb133-431"><a href="#cb133-431" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-432"><a href="#cb133-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-433"><a href="#cb133-433" aria-hidden="true" tabindex="-1"></a>First, we can use the <span class="in">`glm()`</span> function to fit model <span class="in">`glm.fit1`</span> which includes all three independent variables: <span class="in">`student`</span>, <span class="in">`balance`</span> and <span class="in">`income`</span>, with all the observations. </span>
<span id="cb133-434"><a href="#cb133-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-437"><a href="#cb133-437" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-438"><a href="#cb133-438" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(glm.fit1)</span>
<span id="cb133-439"><a href="#cb133-439" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(glm.fit1)</span>
<span id="cb133-440"><a href="#cb133-440" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="fu">coef</span>(glm.fit1))</span>
<span id="cb133-441"><a href="#cb133-441" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-442"><a href="#cb133-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-443"><a href="#cb133-443" aria-hidden="true" tabindex="-1"></a>We can use the function <span class="in">`summary()`</span> to obtain the coefficients, their associated p-values, model AIC and residual deviance. The function <span class="in">`exp()`</span> calculates **odds ratio** of the coefficients.</span>
<span id="cb133-444"><a href="#cb133-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-445"><a href="#cb133-445" aria-hidden="true" tabindex="-1"></a><span class="fu">### 80/20 Hold-out Logistic Regression Model</span></span>
<span id="cb133-446"><a href="#cb133-446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-449"><a href="#cb133-449" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-450"><a href="#cb133-450" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb133-451"><a href="#cb133-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-452"><a href="#cb133-452" aria-hidden="true" tabindex="-1"></a><span class="co"># 80/20 hold-out re-sampling</span></span>
<span id="cb133-453"><a href="#cb133-453" aria-hidden="true" tabindex="-1"></a><span class="co"># indices of 80% train data </span></span>
<span id="cb133-454"><a href="#cb133-454" aria-hidden="true" tabindex="-1"></a>train<span class="ot">=</span><span class="fu">sample</span>(<span class="fu">nrow</span>(Default),<span class="fu">nrow</span>(Default)<span class="sc">*</span><span class="fl">0.8</span>)</span>
<span id="cb133-455"><a href="#cb133-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-456"><a href="#cb133-456" aria-hidden="true" tabindex="-1"></a><span class="co"># indices 20% test data</span></span>
<span id="cb133-457"><a href="#cb133-457" aria-hidden="true" tabindex="-1"></a>Default.test<span class="ot">=</span>Default[<span class="sc">-</span>train, ]</span>
<span id="cb133-458"><a href="#cb133-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-459"><a href="#cb133-459" aria-hidden="true" tabindex="-1"></a><span class="co"># y-values (default variable) of the 20% test data</span></span>
<span id="cb133-460"><a href="#cb133-460" aria-hidden="true" tabindex="-1"></a>test.truevalue<span class="ot">=</span>default[<span class="sc">-</span>train]</span>
<span id="cb133-461"><a href="#cb133-461" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-462"><a href="#cb133-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-463"><a href="#cb133-463" aria-hidden="true" tabindex="-1"></a>We next evaluate the prediction accuracy of this model. We use the <span class="in">`sample()`</span> function to split the original data set into one training set and one test set. We randomly select 80% of the observations for training and</span>
<span id="cb133-464"><a href="#cb133-464" aria-hidden="true" tabindex="-1"></a>the remaining in the test set, <span class="in">`Default.test`</span>. And save the true value of the testing set in the vector <span class="in">`test.truevalue`</span>.</span>
<span id="cb133-465"><a href="#cb133-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-466"><a href="#cb133-466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-469"><a href="#cb133-469" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-470"><a href="#cb133-470" aria-hidden="true" tabindex="-1"></a>glm.fit2<span class="ot">=</span><span class="fu">glm</span>(default<span class="sc">~</span>balance<span class="sc">+</span>student<span class="sc">+</span>income,</span>
<span id="cb133-471"><a href="#cb133-471" aria-hidden="true" tabindex="-1"></a>             <span class="at">data=</span>Default,</span>
<span id="cb133-472"><a href="#cb133-472" aria-hidden="true" tabindex="-1"></a>             <span class="at">subset=</span>train,</span>
<span id="cb133-473"><a href="#cb133-473" aria-hidden="true" tabindex="-1"></a>             <span class="at">family=</span>binomial)</span>
<span id="cb133-474"><a href="#cb133-474" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-475"><a href="#cb133-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-476"><a href="#cb133-476" aria-hidden="true" tabindex="-1"></a>We fit the data with all three independent variables into a logistic regression model <span class="in">`glm.fit2`</span>. The *`subset=train`* option in <span class="in">`glm()`</span> is to fit a regression using only the observations corresponding to the subset.</span>
<span id="cb133-477"><a href="#cb133-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-478"><a href="#cb133-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-481"><a href="#cb133-481" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-482"><a href="#cb133-482" aria-hidden="true" tabindex="-1"></a>glm.probs2<span class="ot">=</span><span class="fu">predict</span>(glm.fit2,Default.test, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb133-483"><a href="#cb133-483" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-484"><a href="#cb133-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-485"><a href="#cb133-485" aria-hidden="true" tabindex="-1"></a>We evaluate the performance of the model using the test set (Default.test). We use the function <span class="in">`predict()`</span> to calculate the *predicted probabilities* of the **default** in the test set and store them to <span class="in">`glm.pred2`</span>. The <span class="in">`type="response"`</span> option tells R to output probabilities not the logit.</span>
<span id="cb133-486"><a href="#cb133-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-487"><a href="#cb133-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-490"><a href="#cb133-490" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-491"><a href="#cb133-491" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: true</span></span>
<span id="cb133-492"><a href="#cb133-492" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb133-493"><a href="#cb133-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-494"><a href="#cb133-494" aria-hidden="true" tabindex="-1"></a><span class="fu">contrasts</span>(Default<span class="sc">$</span>default)</span>
<span id="cb133-495"><a href="#cb133-495" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-496"><a href="#cb133-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-497"><a href="#cb133-497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-498"><a href="#cb133-498" aria-hidden="true" tabindex="-1"></a>R assigned <span class="in">`No=0`</span> and <span class="in">`Yes=1`</span> in the <span class="in">`default`</span> variable.  This means the our classifiers for the model is defined as: </span>
<span id="cb133-499"><a href="#cb133-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-500"><a href="#cb133-500" aria-hidden="true" tabindex="-1"></a>$$\hat{C}(x) = \left<span class="sc">\{</span></span>
<span id="cb133-501"><a href="#cb133-501" aria-hidden="true" tabindex="-1"></a>  \begin{matrix}</span>
<span id="cb133-502"><a href="#cb133-502" aria-hidden="true" tabindex="-1"></a>  1 \ \text{'above'} &amp; \hat{p}(x) &gt; 0.5 <span class="sc">\\</span></span>
<span id="cb133-503"><a href="#cb133-503" aria-hidden="true" tabindex="-1"></a>  0 \ \text{'below'} &amp; \hat{p}(x) \le 0.5</span>
<span id="cb133-504"><a href="#cb133-504" aria-hidden="true" tabindex="-1"></a>  \end{matrix}</span>
<span id="cb133-505"><a href="#cb133-505" aria-hidden="true" tabindex="-1"></a>  \right.</span>
<span id="cb133-506"><a href="#cb133-506" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb133-507"><a href="#cb133-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-508"><a href="#cb133-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-511"><a href="#cb133-511" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-512"><a href="#cb133-512" aria-hidden="true" tabindex="-1"></a>glm.pred2<span class="ot">=</span><span class="fu">rep</span>(<span class="st">"No"</span>,<span class="dv">2000</span>)</span>
<span id="cb133-513"><a href="#cb133-513" aria-hidden="true" tabindex="-1"></a>glm.pred2[glm.probs2<span class="sc">&gt;</span>.<span class="dv">5</span>]<span class="ot">=</span><span class="st">"Yes"</span></span>
<span id="cb133-514"><a href="#cb133-514" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-515"><a href="#cb133-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-516"><a href="#cb133-516" aria-hidden="true" tabindex="-1"></a>We convert the predicted probabilities into a binary class label, <span class="in">`Yes`</span> or <span class="in">`No`</span>. The following commands create a vector of class predictions based on whether the predicted probability is greater than or less than <span class="in">`0.5`</span>.</span>
<span id="cb133-517"><a href="#cb133-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-520"><a href="#cb133-520" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-521"><a href="#cb133-521" aria-hidden="true" tabindex="-1"></a><span class="co"># a more concise code is to use ifelse()</span></span>
<span id="cb133-522"><a href="#cb133-522" aria-hidden="true" tabindex="-1"></a>glm.pred2<span class="ot">=</span><span class="fu">ifelse</span>(glm.probs2 <span class="sc">&gt;</span> <span class="fl">0.5</span>, <span class="st">'Yes'</span>, <span class="st">'No'</span>)</span>
<span id="cb133-523"><a href="#cb133-523" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-524"><a href="#cb133-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-525"><a href="#cb133-525" aria-hidden="true" tabindex="-1"></a>Based on the classifier, the predicted probabilities:</span>
<span id="cb133-526"><a href="#cb133-526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-527"><a href="#cb133-527" aria-hidden="true" tabindex="-1"></a>$$\hat{p}(x) = \hat{P}(Y=1 | X=x)$$</span>
<span id="cb133-528"><a href="#cb133-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-529"><a href="#cb133-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-530"><a href="#cb133-530" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Prediction Accuracy of 80/20 Hold-out {#sec-3accuracy}</span></span>
<span id="cb133-531"><a href="#cb133-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-534"><a href="#cb133-534" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-535"><a href="#cb133-535" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(glm.pred2,test.truevalue)</span>
<span id="cb133-536"><a href="#cb133-536" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(glm.pred2<span class="sc">==</span>test.truevalue)</span>
<span id="cb133-537"><a href="#cb133-537" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-538"><a href="#cb133-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-539"><a href="#cb133-539" aria-hidden="true" tabindex="-1"></a>The <span class="in">`table()`</span> function produce a *confusion matrix* to determine how many observations were correctly classified. We then use `mean()` function to calculate the *accuracy of the prediction*.</span>
<span id="cb133-540"><a href="#cb133-540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-541"><a href="#cb133-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-542"><a href="#cb133-542" aria-hidden="true" tabindex="-1"></a><span class="fu">### Cross-Validation Logistic Regression Model</span></span>
<span id="cb133-543"><a href="#cb133-543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-546"><a href="#cb133-546" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-547"><a href="#cb133-547" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb133-548"><a href="#cb133-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-549"><a href="#cb133-549" aria-hidden="true" tabindex="-1"></a><span class="co"># set number of folds</span></span>
<span id="cb133-550"><a href="#cb133-550" aria-hidden="true" tabindex="-1"></a>k<span class="ot">=</span><span class="dv">5</span></span>
<span id="cb133-551"><a href="#cb133-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-552"><a href="#cb133-552" aria-hidden="true" tabindex="-1"></a><span class="co"># randomly assign indices to folds</span></span>
<span id="cb133-553"><a href="#cb133-553" aria-hidden="true" tabindex="-1"></a>folds<span class="ot">=</span><span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>k,<span class="fu">nrow</span>(Default),<span class="at">replace=</span><span class="cn">TRUE</span>)</span>
<span id="cb133-554"><a href="#cb133-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-555"><a href="#cb133-555" aria-hidden="true" tabindex="-1"></a><span class="co"># first 10 and last 10 fold values</span></span>
<span id="cb133-556"><a href="#cb133-556" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">head</span>(folds, <span class="at">n=</span><span class="dv">10</span>),<span class="st">"..."</span> ,<span class="fu">tail</span>(folds, <span class="at">n=</span><span class="dv">10</span>))</span>
<span id="cb133-557"><a href="#cb133-557" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-558"><a href="#cb133-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-559"><a href="#cb133-559" aria-hidden="true" tabindex="-1"></a>We next evaluate the 5-fold cross-validation prediction of the model.  Split data into k=5-folds.  The output shows the first 10 and last 10 fold assignment.  These are the first 10 and the last 10 rows (or index) of the data. </span>
<span id="cb133-560"><a href="#cb133-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-563"><a href="#cb133-563" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-564"><a href="#cb133-564" aria-hidden="true" tabindex="-1"></a><span class="co"># zero vectors to hold accuracy values of cv method</span></span>
<span id="cb133-565"><a href="#cb133-565" aria-hidden="true" tabindex="-1"></a>accuracy<span class="ot">=</span><span class="fu">rep</span>(<span class="dv">0</span>,k)</span>
<span id="cb133-566"><a href="#cb133-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-567"><a href="#cb133-567" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>k)</span>
<span id="cb133-568"><a href="#cb133-568" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb133-569"><a href="#cb133-569" aria-hidden="true" tabindex="-1"></a>  <span class="co"># cv logistic reg model of train data</span></span>
<span id="cb133-570"><a href="#cb133-570" aria-hidden="true" tabindex="-1"></a>  glm.fit3<span class="ot">=</span><span class="fu">glm</span>(default<span class="sc">~</span>balance<span class="sc">+</span>student<span class="sc">+</span>income, </span>
<span id="cb133-571"><a href="#cb133-571" aria-hidden="true" tabindex="-1"></a>               <span class="at">family=</span><span class="st">"binomial"</span>,</span>
<span id="cb133-572"><a href="#cb133-572" aria-hidden="true" tabindex="-1"></a>               <span class="at">data=</span>Default[folds<span class="sc">!=</span>i,])</span>
<span id="cb133-573"><a href="#cb133-573" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb133-574"><a href="#cb133-574" aria-hidden="true" tabindex="-1"></a>  <span class="co"># assign the current ith iteration as the test data</span></span>
<span id="cb133-575"><a href="#cb133-575" aria-hidden="true" tabindex="-1"></a>  Default.test<span class="ot">=</span>Default[folds<span class="sc">==</span>i, ]</span>
<span id="cb133-576"><a href="#cb133-576" aria-hidden="true" tabindex="-1"></a>  <span class="co"># obtain the probabilities using the test data</span></span>
<span id="cb133-577"><a href="#cb133-577" aria-hidden="true" tabindex="-1"></a>  glm.probs3<span class="ot">=</span><span class="fu">predict</span>(glm.fit3,Default.test, </span>
<span id="cb133-578"><a href="#cb133-578" aria-hidden="true" tabindex="-1"></a>                     <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb133-579"><a href="#cb133-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-580"><a href="#cb133-580" aria-hidden="true" tabindex="-1"></a>  glm.pred3<span class="ot">=</span><span class="fu">rep</span>(<span class="st">"No"</span>, <span class="fu">nrow</span>(Default[folds<span class="sc">==</span>i,]))</span>
<span id="cb133-581"><a href="#cb133-581" aria-hidden="true" tabindex="-1"></a>  glm.pred3[glm.probs3<span class="sc">&gt;</span>.<span class="dv">5</span>]<span class="ot">=</span><span class="st">"yes"</span></span>
<span id="cb133-582"><a href="#cb133-582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-583"><a href="#cb133-583" aria-hidden="true" tabindex="-1"></a>  <span class="co"># y-value (default variable) of the test data in the ith iteration</span></span>
<span id="cb133-584"><a href="#cb133-584" aria-hidden="true" tabindex="-1"></a>  test.truevalue<span class="ot">=</span>default[folds<span class="sc">==</span>i]</span>
<span id="cb133-585"><a href="#cb133-585" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb133-586"><a href="#cb133-586" aria-hidden="true" tabindex="-1"></a>  <span class="co"># calculate the accuracy</span></span>
<span id="cb133-587"><a href="#cb133-587" aria-hidden="true" tabindex="-1"></a>  accuracy[i]<span class="ot">=</span><span class="fu">mean</span>(glm.pred3<span class="sc">==</span>test.truevalue)</span>
<span id="cb133-588"><a href="#cb133-588" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb133-589"><a href="#cb133-589" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-590"><a href="#cb133-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-591"><a href="#cb133-591" aria-hidden="true" tabindex="-1"></a>We create a vector to store the accuracy result for each fold. We set the initial values for this vector as zero.  R treats logical <span class="in">`TRUE=1`</span> and <span class="in">`FALSE=0`</span>.  So the <span class="in">`mean(glm.pred3==test.truevalue)`</span> tests if the actual value of <span class="in">`default`</span> is predicted accurately in <span class="in">`glm.pred3`</span> in each row.  If they match up, then the return value is TRUE=1, if they do not, then the return value is FALSE=0.  At each iteration, the prediction accuracy calculated by obtaining the average and is stored into <span class="in">`accuracy[i]`</span></span>
<span id="cb133-592"><a href="#cb133-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-593"><a href="#cb133-593" aria-hidden="true" tabindex="-1"></a><span class="fu">### Prediction Accuracy of CV Logistic Regression</span></span>
<span id="cb133-594"><a href="#cb133-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-597"><a href="#cb133-597" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-598"><a href="#cb133-598" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(accuracy)</span>
<span id="cb133-599"><a href="#cb133-599" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-600"><a href="#cb133-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-601"><a href="#cb133-601" aria-hidden="true" tabindex="-1"></a>Then we calculate the accuracy of the CV Logistic model by obtaining the grand average accuracy.</span>
<span id="cb133-602"><a href="#cb133-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-603"><a href="#cb133-603" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-604"><a href="#cb133-604" aria-hidden="true" tabindex="-1"></a><span class="fu">## KNN</span></span>
<span id="cb133-605"><a href="#cb133-605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-608"><a href="#cb133-608" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-609"><a href="#cb133-609" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(class)</span>
<span id="cb133-610"><a href="#cb133-610" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-611"><a href="#cb133-611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-612"><a href="#cb133-612" aria-hidden="true" tabindex="-1"></a><span class="fu">### Data Scaling</span></span>
<span id="cb133-613"><a href="#cb133-613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-616"><a href="#cb133-616" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-617"><a href="#cb133-617" aria-hidden="true" tabindex="-1"></a>standardized.balance<span class="ot">=</span><span class="fu">scale</span>(balance)</span>
<span id="cb133-618"><a href="#cb133-618" aria-hidden="true" tabindex="-1"></a>standardized.income<span class="ot">=</span><span class="fu">scale</span>(income)</span>
<span id="cb133-619"><a href="#cb133-619" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-620"><a href="#cb133-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-621"><a href="#cb133-621" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-622"><a href="#cb133-622" aria-hidden="true" tabindex="-1"></a>We first normalize the two quantitative input variables balance and income so that they would be on a comparable scale. The function <span class="in">`scale()`</span> **standardizes** the quantitative variables.</span>
<span id="cb133-623"><a href="#cb133-623" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-624"><a href="#cb133-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-627"><a href="#cb133-627" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-628"><a href="#cb133-628" aria-hidden="true" tabindex="-1"></a>Input.standard<span class="ot">=</span><span class="fu">cbind</span>(standardized.balance,standardized.income,student)</span>
<span id="cb133-629"><a href="#cb133-629" aria-hidden="true" tabindex="-1"></a>accuracy<span class="ot">=</span><span class="fu">matrix</span>(<span class="dv">0</span>,<span class="dv">10</span>,<span class="dv">5</span>)</span>
<span id="cb133-630"><a href="#cb133-630" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-631"><a href="#cb133-631" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-632"><a href="#cb133-632" aria-hidden="true" tabindex="-1"></a>Then we use the function <span class="in">`cbind()`</span> to combine the two standardized variables and the qualitative input</span>
<span id="cb133-633"><a href="#cb133-633" aria-hidden="true" tabindex="-1"></a>variable together.</span>
<span id="cb133-634"><a href="#cb133-634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-637"><a href="#cb133-637" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-638"><a href="#cb133-638" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb133-639"><a href="#cb133-639" aria-hidden="true" tabindex="-1"></a>folds<span class="ot">=</span><span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,<span class="fu">nrow</span>(Input.standard),<span class="at">replace=</span><span class="cn">TRUE</span>)</span>
<span id="cb133-640"><a href="#cb133-640" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-641"><a href="#cb133-641" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>) <span class="co"># 10 neighbors considered</span></span>
<span id="cb133-642"><a href="#cb133-642" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb133-643"><a href="#cb133-643" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>) <span class="co"># for each fold</span></span>
<span id="cb133-644"><a href="#cb133-644" aria-hidden="true" tabindex="-1"></a>  {</span>
<span id="cb133-645"><a href="#cb133-645" aria-hidden="true" tabindex="-1"></a>    <span class="co"># train data indices </span></span>
<span id="cb133-646"><a href="#cb133-646" aria-hidden="true" tabindex="-1"></a>    train.standard<span class="ot">=</span>Input.standard[folds<span class="sc">!=</span>i,]</span>
<span id="cb133-647"><a href="#cb133-647" aria-hidden="true" tabindex="-1"></a>    <span class="co"># test data indices</span></span>
<span id="cb133-648"><a href="#cb133-648" aria-hidden="true" tabindex="-1"></a>    test.standard<span class="ot">=</span>Input.standard[folds<span class="sc">==</span>i,]</span>
<span id="cb133-649"><a href="#cb133-649" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb133-650"><a href="#cb133-650" aria-hidden="true" tabindex="-1"></a>    <span class="co"># y-values (default var) of train data</span></span>
<span id="cb133-651"><a href="#cb133-651" aria-hidden="true" tabindex="-1"></a>    train.truevalue<span class="ot">=</span>default[folds<span class="sc">!=</span>i]</span>
<span id="cb133-652"><a href="#cb133-652" aria-hidden="true" tabindex="-1"></a>    <span class="co"># y-values (default var) of test data </span></span>
<span id="cb133-653"><a href="#cb133-653" aria-hidden="true" tabindex="-1"></a>    test.truevalue<span class="ot">=</span>default[folds<span class="sc">==</span>i]</span>
<span id="cb133-654"><a href="#cb133-654" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb133-655"><a href="#cb133-655" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb133-656"><a href="#cb133-656" aria-hidden="true" tabindex="-1"></a>    knn.pred<span class="ot">=</span><span class="fu">knn</span>(<span class="at">train=</span>train.standard,</span>
<span id="cb133-657"><a href="#cb133-657" aria-hidden="true" tabindex="-1"></a>                 <span class="at">test=</span>test.standard,</span>
<span id="cb133-658"><a href="#cb133-658" aria-hidden="true" tabindex="-1"></a>                 <span class="at">cl=</span>train.truevalue,</span>
<span id="cb133-659"><a href="#cb133-659" aria-hidden="true" tabindex="-1"></a>                 <span class="at">k=</span>j)</span>
<span id="cb133-660"><a href="#cb133-660" aria-hidden="true" tabindex="-1"></a>    accuracy[j,i]<span class="ot">=</span><span class="fu">mean</span>(knn.pred<span class="sc">==</span>test.truevalue)</span>
<span id="cb133-661"><a href="#cb133-661" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb133-662"><a href="#cb133-662" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb133-663"><a href="#cb133-663" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-664"><a href="#cb133-664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-665"><a href="#cb133-665" aria-hidden="true" tabindex="-1"></a>To use KNN, we need to determine K. We can use 5-fold cross-validation to select the best K from <span class="in">`[1,10]`</span>. Thus, we first create a matrix to store the accuracy results for five folds and ten different K values. We set the initial values for this matrix as zero.</span>
<span id="cb133-666"><a href="#cb133-666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-667"><a href="#cb133-667" aria-hidden="true" tabindex="-1"></a><span class="in">`train.standard`</span> is the input matrix of the training set and test.standard is the input matrix of the testing set.  <span class="in">`train.truevalue`</span> is the original value of default in the training set and <span class="in">`test.truevalue`</span> is the true value of</span>
<span id="cb133-668"><a href="#cb133-668" aria-hidden="true" tabindex="-1"></a>default in the testing set. For each observation in the testing set, the knn function can calculate its distance with each observation in the training set based on <span class="in">`train.standard`</span> and <span class="in">`test.standard`</span>. Given <span class="in">`k=j`</span>, it selects the <span class="in">`k`</span> most nearest neighbors, and use their default values (based on <span class="in">`train.truevalue`</span>) to predict the default values in the testing set. In the knn function, we specify the number of neighbors in the option <span class="in">`k=j`</span>. The output of this loop is the prediction accuracy</span>
<span id="cb133-669"><a href="#cb133-669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-670"><a href="#cb133-670" aria-hidden="true" tabindex="-1"></a><span class="fu">### Accuracy of KNN Model</span></span>
<span id="cb133-671"><a href="#cb133-671" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-674"><a href="#cb133-674" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-675"><a href="#cb133-675" aria-hidden="true" tabindex="-1"></a>cv.accuracy<span class="ot">=</span><span class="fu">apply</span>(accuracy,<span class="dv">1</span>,mean)</span>
<span id="cb133-676"><a href="#cb133-676" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-677"><a href="#cb133-677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-678"><a href="#cb133-678" aria-hidden="true" tabindex="-1"></a>Then we calculate the average cross-validation accuracy for each <span class="in">`K`</span>.</span>
<span id="cb133-679"><a href="#cb133-679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-680"><a href="#cb133-680" aria-hidden="true" tabindex="-1"></a><span class="fu"># Classification: CART, Bagging &amp; Random Forest {#sec-4class2}</span></span>
<span id="cb133-681"><a href="#cb133-681" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-682"><a href="#cb133-682" aria-hidden="true" tabindex="-1"></a><span class="fu">## Load Data</span></span>
<span id="cb133-683"><a href="#cb133-683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-686"><a href="#cb133-686" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-687"><a href="#cb133-687" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb133-688"><a href="#cb133-688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-689"><a href="#cb133-689" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>())</span>
<span id="cb133-690"><a href="#cb133-690" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tree)</span>
<span id="cb133-691"><a href="#cb133-691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-692"><a href="#cb133-692" aria-hidden="true" tabindex="-1"></a>iris<span class="ot">&lt;-</span><span class="fu">read.csv</span>(<span class="at">file=</span><span class="st">"../raw_data/iris.csv"</span>,</span>
<span id="cb133-693"><a href="#cb133-693" aria-hidden="true" tabindex="-1"></a>               <span class="at">header=</span>T, </span>
<span id="cb133-694"><a href="#cb133-694" aria-hidden="true" tabindex="-1"></a>               <span class="at">stringsAsFactors=</span><span class="cn">TRUE</span>)</span>
<span id="cb133-695"><a href="#cb133-695" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(iris)</span>
<span id="cb133-696"><a href="#cb133-696" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(iris)</span>
<span id="cb133-697"><a href="#cb133-697" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(iris)</span>
<span id="cb133-698"><a href="#cb133-698" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-699"><a href="#cb133-699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-700"><a href="#cb133-700" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-701"><a href="#cb133-701" aria-hidden="true" tabindex="-1"></a>It contains 3 classes of a total 150 instances. Each class refers to a type of iris plant. </span>
<span id="cb133-702"><a href="#cb133-702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-703"><a href="#cb133-703" aria-hidden="true" tabindex="-1"></a><span class="fu">## 80/20 Hold-out Classification Tree</span></span>
<span id="cb133-704"><a href="#cb133-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-707"><a href="#cb133-707" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-708"><a href="#cb133-708" aria-hidden="true" tabindex="-1"></a><span class="co"># reproduceable random sampling seed</span></span>
<span id="cb133-709"><a href="#cb133-709" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb133-710"><a href="#cb133-710" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-711"><a href="#cb133-711" aria-hidden="true" tabindex="-1"></a><span class="co"># indices of the traning data (80%)</span></span>
<span id="cb133-712"><a href="#cb133-712" aria-hidden="true" tabindex="-1"></a>train<span class="ot">=</span><span class="fu">sample</span>(<span class="fu">nrow</span>(iris),<span class="fu">nrow</span>(iris)<span class="sc">*</span><span class="fl">0.8</span>)</span>
<span id="cb133-713"><a href="#cb133-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-714"><a href="#cb133-714" aria-hidden="true" tabindex="-1"></a><span class="co"># tree model of the training data</span></span>
<span id="cb133-715"><a href="#cb133-715" aria-hidden="true" tabindex="-1"></a>tree.model<span class="ot">=</span><span class="fu">tree</span>(Species<span class="sc">~</span>.,iris,<span class="at">subset =</span>train)</span>
<span id="cb133-716"><a href="#cb133-716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-717"><a href="#cb133-717" aria-hidden="true" tabindex="-1"></a><span class="co"># indices of the test data (20%)</span></span>
<span id="cb133-718"><a href="#cb133-718" aria-hidden="true" tabindex="-1"></a>iris.test<span class="ot">=</span>iris[<span class="sc">-</span>train,]</span>
<span id="cb133-719"><a href="#cb133-719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-720"><a href="#cb133-720" aria-hidden="true" tabindex="-1"></a><span class="co"># values of the target variable (Species variable)</span></span>
<span id="cb133-721"><a href="#cb133-721" aria-hidden="true" tabindex="-1"></a>Species.test<span class="ot">=</span>Species[<span class="sc">-</span>train]</span>
<span id="cb133-722"><a href="#cb133-722" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-723"><a href="#cb133-723" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-724"><a href="#cb133-724" aria-hidden="true" tabindex="-1"></a>We first create a training set, and fit the tree using the training set.</span>
<span id="cb133-725"><a href="#cb133-725" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-728"><a href="#cb133-728" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-729"><a href="#cb133-729" aria-hidden="true" tabindex="-1"></a>cv.model<span class="ot">=</span><span class="fu">cv.tree</span>(<span class="at">object=</span>tree.model, </span>
<span id="cb133-730"><a href="#cb133-730" aria-hidden="true" tabindex="-1"></a>                 <span class="at">K=</span><span class="dv">10</span>, <span class="co"># k-fold cross validation</span></span>
<span id="cb133-731"><a href="#cb133-731" aria-hidden="true" tabindex="-1"></a>                 <span class="at">FUN=</span>prune.misclass)</span>
<span id="cb133-732"><a href="#cb133-732" aria-hidden="true" tabindex="-1"></a>cv.model</span>
<span id="cb133-733"><a href="#cb133-733" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-734"><a href="#cb133-734" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-735"><a href="#cb133-735" aria-hidden="true" tabindex="-1"></a>We use <span class="in">`cv.tree()`</span> to perform 10-fold cross validation, <span class="in">`K=10`</span>,  to find the best subtree or the optimal way to prune the tree.  Although the re-sampling method is 80/20 holdout, <span class="in">`cv.tree()`</span> does cross validation internally. </span>
<span id="cb133-736"><a href="#cb133-736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-739"><a href="#cb133-739" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-740"><a href="#cb133-740" aria-hidden="true" tabindex="-1"></a><span class="co"># prune tree model</span></span>
<span id="cb133-741"><a href="#cb133-741" aria-hidden="true" tabindex="-1"></a>prune.model<span class="ot">=</span><span class="fu">prune.tree</span>(<span class="at">tree=</span>tree.model,</span>
<span id="cb133-742"><a href="#cb133-742" aria-hidden="true" tabindex="-1"></a>                       <span class="at">best=</span><span class="dv">5</span>) <span class="co"># number of terminal nodes</span></span>
<span id="cb133-743"><a href="#cb133-743" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(prune.model)</span>
<span id="cb133-744"><a href="#cb133-744" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(prune.model,<span class="at">pretty=</span><span class="dv">0</span>)</span>
<span id="cb133-745"><a href="#cb133-745" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-746"><a href="#cb133-746" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-747"><a href="#cb133-747" aria-hidden="true" tabindex="-1"></a>We prune tree to the size with the lowest cross-validation error rate using the <span class="in">`prune.tree()`</span> function and plot the tree. We use the argument <span class="in">`FUN=prune.misclass`</span> since it is the classification tree. It indicates that we want the classification error rate to guide the cross-validation and pruning process, rather than the default - deviance.</span>
<span id="cb133-748"><a href="#cb133-748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-749"><a href="#cb133-749" aria-hidden="true" tabindex="-1"></a><span class="fu">### Performance by Confusion Matrix</span></span>
<span id="cb133-750"><a href="#cb133-750" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-753"><a href="#cb133-753" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-754"><a href="#cb133-754" aria-hidden="true" tabindex="-1"></a>prunetree.pred<span class="ot">=</span><span class="fu">predict</span>(prune.model, <span class="co"># pruned tree model</span></span>
<span id="cb133-755"><a href="#cb133-755" aria-hidden="true" tabindex="-1"></a>                       iris.test, <span class="co"># apply pruned tree model on test data</span></span>
<span id="cb133-756"><a href="#cb133-756" aria-hidden="true" tabindex="-1"></a>                       <span class="at">type=</span><span class="st">"class"</span>) <span class="co"># classification</span></span>
<span id="cb133-757"><a href="#cb133-757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-758"><a href="#cb133-758" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(prunetree.pred,Species.test)</span>
<span id="cb133-759"><a href="#cb133-759" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-760"><a href="#cb133-760" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-761"><a href="#cb133-761" aria-hidden="true" tabindex="-1"></a>Then we use the pruned tree to make predictions in the testing set and calculate the confusion matrix.</span>
<span id="cb133-762"><a href="#cb133-762" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-763"><a href="#cb133-763" aria-hidden="true" tabindex="-1"></a><span class="fu">## Regression Tree</span></span>
<span id="cb133-764"><a href="#cb133-764" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-765"><a href="#cb133-765" aria-hidden="true" tabindex="-1"></a><span class="fu">### Load data</span></span>
<span id="cb133-766"><a href="#cb133-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-769"><a href="#cb133-769" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-770"><a href="#cb133-770" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>())</span>
<span id="cb133-771"><a href="#cb133-771" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-772"><a href="#cb133-772" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tree)</span>
<span id="cb133-773"><a href="#cb133-773" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-774"><a href="#cb133-774" aria-hidden="true" tabindex="-1"></a>Boston<span class="ot">=</span><span class="fu">read.csv</span>(<span class="st">"../raw_data/Boston.csv"</span>,<span class="at">header=</span>T)</span>
<span id="cb133-775"><a href="#cb133-775" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Boston)</span>
<span id="cb133-776"><a href="#cb133-776" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(Boston)</span>
<span id="cb133-777"><a href="#cb133-777" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-778"><a href="#cb133-778" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-779"><a href="#cb133-779" aria-hidden="true" tabindex="-1"></a>Load Data <span class="in">`Boston.csv`</span> to object Boston load package <span class="in">`tree`</span> again.</span>
<span id="cb133-780"><a href="#cb133-780" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-781"><a href="#cb133-781" aria-hidden="true" tabindex="-1"></a><span class="fu">### Regression Tree Model</span></span>
<span id="cb133-782"><a href="#cb133-782" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-785"><a href="#cb133-785" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-786"><a href="#cb133-786" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb133-787"><a href="#cb133-787" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-788"><a href="#cb133-788" aria-hidden="true" tabindex="-1"></a><span class="co"># 50/50 holdout resampling</span></span>
<span id="cb133-789"><a href="#cb133-789" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(Boston), <span class="fu">nrow</span>(Boston)<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb133-790"><a href="#cb133-790" aria-hidden="true" tabindex="-1"></a>tree.boston<span class="ot">=</span><span class="fu">tree</span>(medv<span class="sc">~</span>.,Boston,<span class="at">subset=</span>train)</span>
<span id="cb133-791"><a href="#cb133-791" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-792"><a href="#cb133-792" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-793"><a href="#cb133-793" aria-hidden="true" tabindex="-1"></a>There are 506 records with one continuous response <span class="in">`medv`</span> (median house value) and 13 predictors. We again create a training set.</span>
<span id="cb133-794"><a href="#cb133-794" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-795"><a href="#cb133-795" aria-hidden="true" tabindex="-1"></a><span class="fu">### Best Sub-Tree Model</span></span>
<span id="cb133-796"><a href="#cb133-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-799"><a href="#cb133-799" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-800"><a href="#cb133-800" aria-hidden="true" tabindex="-1"></a>cv.boston<span class="ot">=</span><span class="fu">cv.tree</span>(<span class="at">object=</span>tree.boston,</span>
<span id="cb133-801"><a href="#cb133-801" aria-hidden="true" tabindex="-1"></a>                  <span class="at">K=</span><span class="dv">10</span>) <span class="co"># k-fold cross-validation</span></span>
<span id="cb133-802"><a href="#cb133-802" aria-hidden="true" tabindex="-1"></a>cv.boston</span>
<span id="cb133-803"><a href="#cb133-803" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-804"><a href="#cb133-804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-805"><a href="#cb133-805" aria-hidden="true" tabindex="-1"></a>We use the <span class="in">`cv.tree()`</span> function to perform 10-fold cross validation to find the best subtree. _We do not need to specify the argument FUN since it is the regression tree._</span>
<span id="cb133-806"><a href="#cb133-806" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-809"><a href="#cb133-809" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-810"><a href="#cb133-810" aria-hidden="true" tabindex="-1"></a>prune.boston<span class="ot">=</span><span class="fu">prune.tree</span>(tree.boston,</span>
<span id="cb133-811"><a href="#cb133-811" aria-hidden="true" tabindex="-1"></a>                        <span class="at">best=</span><span class="dv">8</span>) <span class="co"># number of terminal nodes</span></span>
<span id="cb133-812"><a href="#cb133-812" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(prune.boston)</span>
<span id="cb133-813"><a href="#cb133-813" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(prune.boston,<span class="at">pretty=</span><span class="dv">0</span>)</span>
<span id="cb133-814"><a href="#cb133-814" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-815"><a href="#cb133-815" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-816"><a href="#cb133-816" aria-hidden="true" tabindex="-1"></a>We prune tree to the optimal size using the <span class="in">`prune.tree()`</span> function and plot the tree.</span>
<span id="cb133-817"><a href="#cb133-817" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-818"><a href="#cb133-818" aria-hidden="true" tabindex="-1"></a><span class="fu">### Tree Model Performance</span></span>
<span id="cb133-819"><a href="#cb133-819" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-822"><a href="#cb133-822" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-823"><a href="#cb133-823" aria-hidden="true" tabindex="-1"></a><span class="co"># assign vector of the target variable medv as test data</span></span>
<span id="cb133-824"><a href="#cb133-824" aria-hidden="true" tabindex="-1"></a>boston.test<span class="ot">=</span>Boston[<span class="sc">-</span>train,<span class="st">"medv"</span>] </span>
<span id="cb133-825"><a href="#cb133-825" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-826"><a href="#cb133-826" aria-hidden="true" tabindex="-1"></a>tree.pred<span class="ot">=</span><span class="fu">predict</span>(prune.boston, <span class="co"># pruned tree model</span></span>
<span id="cb133-827"><a href="#cb133-827" aria-hidden="true" tabindex="-1"></a>                  <span class="at">newdata=</span>Boston[<span class="sc">-</span>train,]) <span class="co"># test data</span></span>
<span id="cb133-828"><a href="#cb133-828" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-829"><a href="#cb133-829" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate MSE</span></span>
<span id="cb133-830"><a href="#cb133-830" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>((tree.pred<span class="sc">-</span>boston.test)<span class="sc">^</span><span class="dv">2</span>) </span>
<span id="cb133-831"><a href="#cb133-831" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-832"><a href="#cb133-832" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-833"><a href="#cb133-833" aria-hidden="true" tabindex="-1"></a>Then we use the pruned tree to make predictions in the testing set and calculate the mean square error (MSE).</span>
<span id="cb133-834"><a href="#cb133-834" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-835"><a href="#cb133-835" aria-hidden="true" tabindex="-1"></a><span class="fu">## Random Forests (FULL) Model</span></span>
<span id="cb133-836"><a href="#cb133-836" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-839"><a href="#cb133-839" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-840"><a href="#cb133-840" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span>
<span id="cb133-841"><a href="#cb133-841" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-842"><a href="#cb133-842" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb133-843"><a href="#cb133-843" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-844"><a href="#cb133-844" aria-hidden="true" tabindex="-1"></a>bag.boston<span class="ot">=</span><span class="fu">randomForest</span>(medv<span class="sc">~</span>., <span class="co"># target/response variable</span></span>
<span id="cb133-845"><a href="#cb133-845" aria-hidden="true" tabindex="-1"></a>                        <span class="at">data=</span>Boston, <span class="co"># df containing the variable of the model</span></span>
<span id="cb133-846"><a href="#cb133-846" aria-hidden="true" tabindex="-1"></a>                        <span class="at">subset=</span>train, <span class="co"># train dataset to model</span></span>
<span id="cb133-847"><a href="#cb133-847" aria-hidden="true" tabindex="-1"></a>                        <span class="at">mtry=</span><span class="dv">13</span>, <span class="co"># number of predictors to use (all 13)</span></span>
<span id="cb133-848"><a href="#cb133-848" aria-hidden="true" tabindex="-1"></a>                        <span class="at">importance=</span><span class="cn">TRUE</span>)</span>
<span id="cb133-849"><a href="#cb133-849" aria-hidden="true" tabindex="-1"></a>bag.boston</span>
<span id="cb133-850"><a href="#cb133-850" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-851"><a href="#cb133-851" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-852"><a href="#cb133-852" aria-hidden="true" tabindex="-1"></a>In the <span class="in">`randomForest()`</span> function, the argument <span class="in">`mtry=13`</span> indicates that *all 13 predictors* should be used, that is bagging. <span class="in">`subset=train`</span> indicates that we train this model only using the training dataset. <span class="in">`importance=TRUE`</span> indicates that the importance of predictors is assessed. <span class="in">`bag.boston`</span> stores the bagging model.</span>
<span id="cb133-853"><a href="#cb133-853" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-854"><a href="#cb133-854" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-855"><a href="#cb133-855" aria-hidden="true" tabindex="-1"></a><span class="fu">### Random Forest (FULL) Model Performance</span></span>
<span id="cb133-856"><a href="#cb133-856" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-859"><a href="#cb133-859" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-860"><a href="#cb133-860" aria-hidden="true" tabindex="-1"></a>yhat.bag <span class="ot">=</span> <span class="fu">predict</span>(bag.boston, <span class="co"># rf model</span></span>
<span id="cb133-861"><a href="#cb133-861" aria-hidden="true" tabindex="-1"></a>                   <span class="at">newdata=</span>Boston[<span class="sc">-</span>train,]) <span class="co"># test data</span></span>
<span id="cb133-862"><a href="#cb133-862" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-863"><a href="#cb133-863" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate MSE mean sq. of the difference predicted and actual</span></span>
<span id="cb133-864"><a href="#cb133-864" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>((yhat.bag<span class="sc">-</span>boston.test)<span class="sc">^</span><span class="dv">2</span>) </span>
<span id="cb133-865"><a href="#cb133-865" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-866"><a href="#cb133-866" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-867"><a href="#cb133-867" aria-hidden="true" tabindex="-1"></a>We next evaluate the performance of bagging by fitting it to the testing dataset Boston<span class="co">[</span><span class="ot">-train,</span><span class="co">]</span>. Then we calculate the MSE.</span>
<span id="cb133-868"><a href="#cb133-868" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-869"><a href="#cb133-869" aria-hidden="true" tabindex="-1"></a><span class="fu">### Random Forest Model</span></span>
<span id="cb133-870"><a href="#cb133-870" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-873"><a href="#cb133-873" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-874"><a href="#cb133-874" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb133-875"><a href="#cb133-875" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-876"><a href="#cb133-876" aria-hidden="true" tabindex="-1"></a><span class="co"># target response medv against any 5 predictors (mtry=5)</span></span>
<span id="cb133-877"><a href="#cb133-877" aria-hidden="true" tabindex="-1"></a>rf.boston<span class="ot">=</span><span class="fu">randomForest</span>(medv<span class="sc">~</span>.,</span>
<span id="cb133-878"><a href="#cb133-878" aria-hidden="true" tabindex="-1"></a>                       <span class="at">data=</span>Boston,</span>
<span id="cb133-879"><a href="#cb133-879" aria-hidden="true" tabindex="-1"></a>                       <span class="at">subset=</span>train,</span>
<span id="cb133-880"><a href="#cb133-880" aria-hidden="true" tabindex="-1"></a>                       <span class="at">mtry=</span><span class="dv">5</span>, <span class="co"># rf regression uses 1/3 of total predictors</span></span>
<span id="cb133-881"><a href="#cb133-881" aria-hidden="true" tabindex="-1"></a>                       <span class="at">importance=</span><span class="cn">TRUE</span>)</span>
<span id="cb133-882"><a href="#cb133-882" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-883"><a href="#cb133-883" aria-hidden="true" tabindex="-1"></a>yhat.rf <span class="ot">=</span> <span class="fu">predict</span>(rf.boston,<span class="at">newdata=</span>Boston[<span class="sc">-</span>train,])</span>
<span id="cb133-884"><a href="#cb133-884" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>((yhat.rf<span class="sc">-</span>boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb133-885"><a href="#cb133-885" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-886"><a href="#cb133-886" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-887"><a href="#cb133-887" aria-hidden="true" tabindex="-1"></a>Now let’s use the function to implement random forest. The *difference is that random forest does not use all input variables in each tree*. It usually uses **p/3 variables for regression trees**  and **$\sqrt{p}$ for classification trees**. Now let’s use <span class="in">`mtry=5`</span>. <span class="in">`rf.boston`</span> stores the random forest model. We test the MSE of this model by comparing the predicted values with the true values.</span>
<span id="cb133-888"><a href="#cb133-888" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-889"><a href="#cb133-889" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-892"><a href="#cb133-892" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-893"><a href="#cb133-893" aria-hidden="true" tabindex="-1"></a><span class="fu">importance</span>(rf.boston)</span>
<span id="cb133-894"><a href="#cb133-894" aria-hidden="true" tabindex="-1"></a><span class="fu">varImpPlot</span>(rf.boston)</span>
<span id="cb133-895"><a href="#cb133-895" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-896"><a href="#cb133-896" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-897"><a href="#cb133-897" aria-hidden="true" tabindex="-1"></a>The importance of each variable can be evaluated using the <span class="in">`importance()`</span> function. The function <span class="in">`varImpPlot()`</span> plots the important measures. Two measures of variable importance are reported. One is based on the mean decrease of accuracy in predictions on the out of bag samples when a given variable is excluded from the model. The second is a measure of the total decrease in node impurity that results from splits over that variable, averaged over all trees.</span>
<span id="cb133-898"><a href="#cb133-898" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-899"><a href="#cb133-899" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-900"><a href="#cb133-900" aria-hidden="true" tabindex="-1"></a><span class="fu"># Clustering</span></span>
<span id="cb133-901"><a href="#cb133-901" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-902"><a href="#cb133-902" aria-hidden="true" tabindex="-1"></a><span class="fu">## Load Data</span></span>
<span id="cb133-903"><a href="#cb133-903" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-906"><a href="#cb133-906" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-907"><a href="#cb133-907" aria-hidden="true" tabindex="-1"></a>iris<span class="ot">&lt;-</span><span class="fu">read.csv</span>(<span class="st">"../raw_data/iris.csv"</span>,</span>
<span id="cb133-908"><a href="#cb133-908" aria-hidden="true" tabindex="-1"></a>               <span class="at">header=</span>T,</span>
<span id="cb133-909"><a href="#cb133-909" aria-hidden="true" tabindex="-1"></a>               <span class="at">stringsAsFactors=</span><span class="cn">TRUE</span>)</span>
<span id="cb133-910"><a href="#cb133-910" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(iris)</span>
<span id="cb133-911"><a href="#cb133-911" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(iris)</span>
<span id="cb133-912"><a href="#cb133-912" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(iris)</span>
<span id="cb133-913"><a href="#cb133-913" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(iris)</span>
<span id="cb133-914"><a href="#cb133-914" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-915"><a href="#cb133-915" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-916"><a href="#cb133-916" aria-hidden="true" tabindex="-1"></a><span class="in">`iris.csv`</span> is a multivariate data set introduced by Ronald Fisher (1936): The use of multiple measurements in taxonomic problem. It contains 3 classes of a total 150 instances. Each class refers to a type of iris plant. There are five variables in this data set: <span class="in">`Sepal.Length, Sepal.Width, Petal.Length, Petal.Width and Species`</span>.</span>
<span id="cb133-917"><a href="#cb133-917" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-920"><a href="#cb133-920" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-921"><a href="#cb133-921" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb133-922"><a href="#cb133-922" aria-hidden="true" tabindex="-1"></a>iris.labs<span class="ot">=</span>iris[,<span class="dv">5</span>]</span>
<span id="cb133-923"><a href="#cb133-923" aria-hidden="true" tabindex="-1"></a>iris.data<span class="ot">=</span>iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>]</span>
<span id="cb133-924"><a href="#cb133-924" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(iris.data)</span>
<span id="cb133-925"><a href="#cb133-925" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-926"><a href="#cb133-926" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-927"><a href="#cb133-927" aria-hidden="true" tabindex="-1"></a>Each instance is labeled with a class. We do not use the class in performing clustering, as it is an unsupervised technique. But after performing clustering, we can check the extent to which these classes agree with the result of the unsupervised technique. Accordingly, we store the label of each instance in the object <span class="in">`iris.labs`</span>. </span>
<span id="cb133-928"><a href="#cb133-928" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-931"><a href="#cb133-931" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-932"><a href="#cb133-932" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb133-933"><a href="#cb133-933" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-934"><a href="#cb133-934" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(iris.labs)</span>
<span id="cb133-935"><a href="#cb133-935" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-936"><a href="#cb133-936" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-937"><a href="#cb133-937" aria-hidden="true" tabindex="-1"></a><span class="in">`table(iris.labs)`</span> shows that we have 50 instances in each class.</span>
<span id="cb133-938"><a href="#cb133-938" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-939"><a href="#cb133-939" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-940"><a href="#cb133-940" aria-hidden="true" tabindex="-1"></a><span class="fu">### Euclidean Distance Method</span></span>
<span id="cb133-941"><a href="#cb133-941" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-944"><a href="#cb133-944" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-945"><a href="#cb133-945" aria-hidden="true" tabindex="-1"></a>data.dist<span class="ot">=</span><span class="fu">dist</span>(iris.data,</span>
<span id="cb133-946"><a href="#cb133-946" aria-hidden="true" tabindex="-1"></a>               <span class="at">method =</span> <span class="st">'euclidean'</span>)</span>
<span id="cb133-947"><a href="#cb133-947" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-948"><a href="#cb133-948" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-949"><a href="#cb133-949" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-950"><a href="#cb133-950" aria-hidden="true" tabindex="-1"></a>Since clustering relies on the distances between clusters, we use the function <span class="in">`dist()`</span> to compute the $150 \times 150$ inter-observation Euclidean distance matrix and store it in the object <span class="in">`data.dist`</span>.</span>
<span id="cb133-951"><a href="#cb133-951" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-952"><a href="#cb133-952" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Hierarchical Clustering </span></span>
<span id="cb133-953"><a href="#cb133-953" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-956"><a href="#cb133-956" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-957"><a href="#cb133-957" aria-hidden="true" tabindex="-1"></a><span class="co"># default uses complete linkage</span></span>
<span id="cb133-958"><a href="#cb133-958" aria-hidden="true" tabindex="-1"></a>hc1<span class="ot">=</span><span class="fu">hclust</span>(<span class="at">d=</span>data.dist)</span>
<span id="cb133-959"><a href="#cb133-959" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-960"><a href="#cb133-960" aria-hidden="true" tabindex="-1"></a><span class="co"># average linkage </span></span>
<span id="cb133-961"><a href="#cb133-961" aria-hidden="true" tabindex="-1"></a>hc2<span class="ot">=</span><span class="fu">hclust</span>(<span class="at">d=</span>data.dist, </span>
<span id="cb133-962"><a href="#cb133-962" aria-hidden="true" tabindex="-1"></a>           <span class="at">method=</span><span class="st">"average"</span>)</span>
<span id="cb133-963"><a href="#cb133-963" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-964"><a href="#cb133-964" aria-hidden="true" tabindex="-1"></a><span class="co"># single linkage</span></span>
<span id="cb133-965"><a href="#cb133-965" aria-hidden="true" tabindex="-1"></a>hc3<span class="ot">=</span><span class="fu">hclust</span>(<span class="at">d=</span>data.dist, </span>
<span id="cb133-966"><a href="#cb133-966" aria-hidden="true" tabindex="-1"></a>           <span class="at">method=</span><span class="st">"single"</span>)</span>
<span id="cb133-967"><a href="#cb133-967" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-968"><a href="#cb133-968" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-969"><a href="#cb133-969" aria-hidden="true" tabindex="-1"></a>The <span class="in">`hclust()`</span> function implements hierarchical clustering. The first parameter in this function is the dissimilarity structure <span class="in">`d=data.dist`</span>, i.e. the distance matrix. The second parameter <span class="in">`method=`</span> is the linkage type, e.g. average, complete, single, or centroid. By default, it is the “complete” linkage type. Thus, hc1 stores the clustering dendrogram using the complete linkage clustering.</span>
<span id="cb133-970"><a href="#cb133-970" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-973"><a href="#cb133-973" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-974"><a href="#cb133-974" aria-hidden="true" tabindex="-1"></a><span class="co"># combine plots in 1x3 display </span></span>
<span id="cb133-975"><a href="#cb133-975" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>)) </span>
<span id="cb133-976"><a href="#cb133-976" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-977"><a href="#cb133-977" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(hc1, <span class="at">main=</span><span class="st">"Complete Linkage"</span>, <span class="at">xlab=</span><span class="st">""</span>, <span class="at">sub=</span><span class="st">""</span>,<span class="at">ylab=</span><span class="st">""</span>)</span>
<span id="cb133-978"><a href="#cb133-978" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(hc2, <span class="at">main=</span><span class="st">"Average Linkage"</span>, <span class="at">xlab=</span><span class="st">""</span>, <span class="at">sub=</span><span class="st">""</span>,<span class="at">ylab=</span><span class="st">""</span>)</span>
<span id="cb133-979"><a href="#cb133-979" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(hc3, <span class="at">main=</span><span class="st">"Single Linkage"</span>, <span class="at">xlab=</span><span class="st">""</span>, <span class="at">sub=</span><span class="st">""</span>,<span class="at">ylab=</span><span class="st">""</span>)</span>
<span id="cb133-980"><a href="#cb133-980" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-981"><a href="#cb133-981" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-982"><a href="#cb133-982" aria-hidden="true" tabindex="-1"></a>We plot the obtained dendrograms using the <span class="in">`plot()`</span> function. The numbers at the bottom of the plot identify each observation. We could see that the choice of linkage certainly affect the results obtained.</span>
<span id="cb133-983"><a href="#cb133-983" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-986"><a href="#cb133-986" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-987"><a href="#cb133-987" aria-hidden="true" tabindex="-1"></a>hc.clusters1<span class="ot">=</span><span class="fu">cutree</span>(hc1,<span class="dv">3</span>)</span>
<span id="cb133-988"><a href="#cb133-988" aria-hidden="true" tabindex="-1"></a>hc.clusters2<span class="ot">=</span><span class="fu">cutree</span>(hc2,<span class="dv">3</span>)</span>
<span id="cb133-989"><a href="#cb133-989" aria-hidden="true" tabindex="-1"></a>hc.clusters3<span class="ot">=</span><span class="fu">cutree</span>(hc3,<span class="dv">3</span>)</span>
<span id="cb133-990"><a href="#cb133-990" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-991"><a href="#cb133-991" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-992"><a href="#cb133-992" aria-hidden="true" tabindex="-1"></a>We need to determine where to cut the dendrogram so as to identify the labels for each observation. This decision has a strong impact on the clustering results. We usually need to try several choices, and use the one with the highest interpretability. In this case, as we already know there are a total of three classes, we can cut them to obtain three clusters using the <span class="in">`cutree()`</span> function.</span>
<span id="cb133-993"><a href="#cb133-993" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-996"><a href="#cb133-996" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-997"><a href="#cb133-997" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb133-998"><a href="#cb133-998" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(hc.clusters1,iris.labs)</span>
<span id="cb133-999"><a href="#cb133-999" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(hc.clusters2,iris.labs)</span>
<span id="cb133-1000"><a href="#cb133-1000" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(hc.clusters3,iris.labs)</span>
<span id="cb133-1001"><a href="#cb133-1001" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-1002"><a href="#cb133-1002" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1003"><a href="#cb133-1003" aria-hidden="true" tabindex="-1"></a>We then compare the cluster labels from all three methods with the original labels. All three linkage methods successfully identify all the flowers of species setosa into cluster 1. But they do not differentiate between virginica and versicolor quite well. The average linkage type looks better than the other two types.</span>
<span id="cb133-1004"><a href="#cb133-1004" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1007"><a href="#cb133-1007" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-1008"><a href="#cb133-1008" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb133-1009"><a href="#cb133-1009" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1010"><a href="#cb133-1010" aria-hidden="true" tabindex="-1"></a><span class="co"># display 2 plots in 1x2 format</span></span>
<span id="cb133-1011"><a href="#cb133-1011" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb133-1012"><a href="#cb133-1012" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1013"><a href="#cb133-1013" aria-hidden="true" tabindex="-1"></a><span class="co"># set color configuration</span></span>
<span id="cb133-1014"><a href="#cb133-1014" aria-hidden="true" tabindex="-1"></a>cols <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"red"</span>,<span class="st">"green"</span>,<span class="st">"blue"</span>)</span>
<span id="cb133-1015"><a href="#cb133-1015" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1016"><a href="#cb133-1016" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(Sepal.Width <span class="sc">~</span> Sepal.Length, </span>
<span id="cb133-1017"><a href="#cb133-1017" aria-hidden="true" tabindex="-1"></a>     <span class="at">data=</span>iris, </span>
<span id="cb133-1018"><a href="#cb133-1018" aria-hidden="true" tabindex="-1"></a>     <span class="at">col=</span>cols[iris<span class="sc">$</span>Species], </span>
<span id="cb133-1019"><a href="#cb133-1019" aria-hidden="true" tabindex="-1"></a>     <span class="at">main=</span><span class="st">"Sepal.Width ~ Sepal.Length"</span>)</span>
<span id="cb133-1020"><a href="#cb133-1020" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="at">x=</span><span class="fl">6.5</span>, <span class="at">y=</span><span class="fl">4.5</span>, </span>
<span id="cb133-1021"><a href="#cb133-1021" aria-hidden="true" tabindex="-1"></a>       <span class="at">legend=</span><span class="fu">levels</span>(iris<span class="sc">$</span>Species), </span>
<span id="cb133-1022"><a href="#cb133-1022" aria-hidden="true" tabindex="-1"></a>       <span class="at">col=</span>cols, </span>
<span id="cb133-1023"><a href="#cb133-1023" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch=</span><span class="dv">1</span>)</span>
<span id="cb133-1024"><a href="#cb133-1024" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1025"><a href="#cb133-1025" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(Petal.Width <span class="sc">~</span> Petal.Length, </span>
<span id="cb133-1026"><a href="#cb133-1026" aria-hidden="true" tabindex="-1"></a>     <span class="at">data=</span>iris, </span>
<span id="cb133-1027"><a href="#cb133-1027" aria-hidden="true" tabindex="-1"></a>     <span class="at">col=</span>cols[iris<span class="sc">$</span>Species],</span>
<span id="cb133-1028"><a href="#cb133-1028" aria-hidden="true" tabindex="-1"></a>     <span class="at">main=</span><span class="st">"Petal.Width ~ Petal.Length"</span>)</span>
<span id="cb133-1029"><a href="#cb133-1029" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="at">x=</span><span class="dv">1</span>, <span class="at">y=</span><span class="fl">2.5</span>, </span>
<span id="cb133-1030"><a href="#cb133-1030" aria-hidden="true" tabindex="-1"></a>       <span class="at">legend=</span><span class="fu">levels</span>(iris<span class="sc">$</span>Species), </span>
<span id="cb133-1031"><a href="#cb133-1031" aria-hidden="true" tabindex="-1"></a>       <span class="at">col=</span>cols, </span>
<span id="cb133-1032"><a href="#cb133-1032" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch=</span><span class="dv">1</span>)</span>
<span id="cb133-1033"><a href="#cb133-1033" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-1034"><a href="#cb133-1034" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1035"><a href="#cb133-1035" aria-hidden="true" tabindex="-1"></a>Based on the above two plots, variables Petal.Length and Petal.Width can better differentiate among the three species. Thus, we re-design all three clustering models using the only two variables.</span>
<span id="cb133-1036"><a href="#cb133-1036" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1037"><a href="#cb133-1037" aria-hidden="true" tabindex="-1"></a><span class="fu">### Hierarchical Clustering Model Comparison on Selected Variables</span></span>
<span id="cb133-1038"><a href="#cb133-1038" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1041"><a href="#cb133-1041" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-1042"><a href="#cb133-1042" aria-hidden="true" tabindex="-1"></a><span class="co"># include only Petal.Length and Petal.Width</span></span>
<span id="cb133-1043"><a href="#cb133-1043" aria-hidden="true" tabindex="-1"></a>iris.data2<span class="ot">=</span>iris[,<span class="dv">3</span><span class="sc">:</span><span class="dv">4</span>]</span>
<span id="cb133-1044"><a href="#cb133-1044" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1045"><a href="#cb133-1045" aria-hidden="true" tabindex="-1"></a><span class="co"># Euclidean distance </span></span>
<span id="cb133-1046"><a href="#cb133-1046" aria-hidden="true" tabindex="-1"></a>data.dist2<span class="ot">=</span><span class="fu">dist</span>(iris.data2, </span>
<span id="cb133-1047"><a href="#cb133-1047" aria-hidden="true" tabindex="-1"></a>                <span class="at">method =</span> <span class="st">'euclidean'</span>)</span>
<span id="cb133-1048"><a href="#cb133-1048" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1049"><a href="#cb133-1049" aria-hidden="true" tabindex="-1"></a><span class="co"># cluster model default is method=complete</span></span>
<span id="cb133-1050"><a href="#cb133-1050" aria-hidden="true" tabindex="-1"></a>newhc1<span class="ot">=</span><span class="fu">hclust</span>(data.dist2)</span>
<span id="cb133-1051"><a href="#cb133-1051" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1052"><a href="#cb133-1052" aria-hidden="true" tabindex="-1"></a><span class="co"># average linkage</span></span>
<span id="cb133-1053"><a href="#cb133-1053" aria-hidden="true" tabindex="-1"></a>newhc2<span class="ot">=</span><span class="fu">hclust</span>(data.dist2, <span class="at">method=</span><span class="st">"average"</span>)</span>
<span id="cb133-1054"><a href="#cb133-1054" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1055"><a href="#cb133-1055" aria-hidden="true" tabindex="-1"></a><span class="co"># single linkage</span></span>
<span id="cb133-1056"><a href="#cb133-1056" aria-hidden="true" tabindex="-1"></a>newhc3<span class="ot">=</span><span class="fu">hclust</span>(data.dist2, <span class="at">method=</span><span class="st">"single"</span>)</span>
<span id="cb133-1057"><a href="#cb133-1057" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-1058"><a href="#cb133-1058" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1059"><a href="#cb133-1059" aria-hidden="true" tabindex="-1"></a>Re-design all three clustering models using the only two variables.</span>
<span id="cb133-1060"><a href="#cb133-1060" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1063"><a href="#cb133-1063" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-1064"><a href="#cb133-1064" aria-hidden="true" tabindex="-1"></a><span class="co"># make it into 3 clusters (groups)</span></span>
<span id="cb133-1065"><a href="#cb133-1065" aria-hidden="true" tabindex="-1"></a>newhc.clusters1<span class="ot">=</span><span class="fu">cutree</span>(newhc1,<span class="dv">3</span>)</span>
<span id="cb133-1066"><a href="#cb133-1066" aria-hidden="true" tabindex="-1"></a>newhc.clusters2<span class="ot">=</span><span class="fu">cutree</span>(newhc2,<span class="dv">3</span>)</span>
<span id="cb133-1067"><a href="#cb133-1067" aria-hidden="true" tabindex="-1"></a>newhc.clusters3<span class="ot">=</span><span class="fu">cutree</span>(newhc3,<span class="dv">3</span>)</span>
<span id="cb133-1068"><a href="#cb133-1068" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-1069"><a href="#cb133-1069" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1070"><a href="#cb133-1070" aria-hidden="true" tabindex="-1"></a>Make into 3 cluster groups on all three methods</span>
<span id="cb133-1071"><a href="#cb133-1071" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1074"><a href="#cb133-1074" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-1075"><a href="#cb133-1075" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb133-1076"><a href="#cb133-1076" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1077"><a href="#cb133-1077" aria-hidden="true" tabindex="-1"></a><span class="co"># analyze difference between difference hierarchical methods</span></span>
<span id="cb133-1078"><a href="#cb133-1078" aria-hidden="true" tabindex="-1"></a><span class="co"># complete linkage</span></span>
<span id="cb133-1079"><a href="#cb133-1079" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(newhc.clusters1,iris.labs) </span>
<span id="cb133-1080"><a href="#cb133-1080" aria-hidden="true" tabindex="-1"></a><span class="co"># average linkage</span></span>
<span id="cb133-1081"><a href="#cb133-1081" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(newhc.clusters2,iris.labs)</span>
<span id="cb133-1082"><a href="#cb133-1082" aria-hidden="true" tabindex="-1"></a><span class="co"># single linkage</span></span>
<span id="cb133-1083"><a href="#cb133-1083" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(newhc.clusters3,iris.labs)</span>
<span id="cb133-1084"><a href="#cb133-1084" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-1085"><a href="#cb133-1085" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1086"><a href="#cb133-1086" aria-hidden="true" tabindex="-1"></a>Now we can see that the clustering algorithm with the average linkage does a much better job. Only five observations in versicolor and one in virginica do not fall in their own cluster.</span>
<span id="cb133-1087"><a href="#cb133-1087" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1088"><a href="#cb133-1088" aria-hidden="true" tabindex="-1"></a><span class="fu">### Plot the best method, Average Linkage</span></span>
<span id="cb133-1089"><a href="#cb133-1089" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1092"><a href="#cb133-1092" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-1093"><a href="#cb133-1093" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb133-1094"><a href="#cb133-1094" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb133-1095"><a href="#cb133-1095" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(newhc2, <span class="at">labels=</span>iris.labs)</span>
<span id="cb133-1096"><a href="#cb133-1096" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="fl">1.3</span>, <span class="at">col=</span><span class="st">"red"</span>)</span>
<span id="cb133-1097"><a href="#cb133-1097" aria-hidden="true" tabindex="-1"></a>newhc2</span>
<span id="cb133-1098"><a href="#cb133-1098" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-1099"><a href="#cb133-1099" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1100"><a href="#cb133-1100" aria-hidden="true" tabindex="-1"></a><span class="fu">## K-Means Clustering</span></span>
<span id="cb133-1101"><a href="#cb133-1101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1104"><a href="#cb133-1104" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-1105"><a href="#cb133-1105" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb133-1106"><a href="#cb133-1106" aria-hidden="true" tabindex="-1"></a>km.out1 <span class="ot">=</span><span class="fu">kmeans</span>(iris.data,</span>
<span id="cb133-1107"><a href="#cb133-1107" aria-hidden="true" tabindex="-1"></a>                <span class="at">centers=</span><span class="dv">3</span>, <span class="co"># number of k-clusters</span></span>
<span id="cb133-1108"><a href="#cb133-1108" aria-hidden="true" tabindex="-1"></a>                <span class="at">nstart=</span><span class="dv">1</span>) <span class="co"># how many random sets</span></span>
<span id="cb133-1109"><a href="#cb133-1109" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-1110"><a href="#cb133-1110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1111"><a href="#cb133-1111" aria-hidden="true" tabindex="-1"></a>In Step 1 of K-means, the initial cluster labels are assigned randomly, we first set a random seed. The function <span class="in">`kmeans()`</span> performs K-means clustering. The first parameter is the data matrix. The second one is the pre-specified <span class="in">`K`</span>, the number of clusters. In this case, we set it as 3. The third parameter, <span class="in">`nstart`</span>, indicates the number of random assignments in Step 1. We first set <span class="in">`nstart=1`</span>, which means that only run the function with one set of initial cluster assignment.</span>
<span id="cb133-1112"><a href="#cb133-1112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1115"><a href="#cb133-1115" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-1116"><a href="#cb133-1116" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb133-1117"><a href="#cb133-1117" aria-hidden="true" tabindex="-1"></a>km.out1</span>
<span id="cb133-1118"><a href="#cb133-1118" aria-hidden="true" tabindex="-1"></a>km.out1<span class="sc">$</span>cluster</span>
<span id="cb133-1119"><a href="#cb133-1119" aria-hidden="true" tabindex="-1"></a>km.out1<span class="sc">$</span>betweenss</span>
<span id="cb133-1120"><a href="#cb133-1120" aria-hidden="true" tabindex="-1"></a>km.out1<span class="sc">$</span>withinss</span>
<span id="cb133-1121"><a href="#cb133-1121" aria-hidden="true" tabindex="-1"></a>km.out1<span class="sc">$</span>tot.withinss</span>
<span id="cb133-1122"><a href="#cb133-1122" aria-hidden="true" tabindex="-1"></a>km.out1<span class="sc">$</span>totss</span>
<span id="cb133-1123"><a href="#cb133-1123" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-1124"><a href="#cb133-1124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1125"><a href="#cb133-1125" aria-hidden="true" tabindex="-1"></a>The kmeans function returns multiple values. <span class="in">`km.out1$cluster`</span> returns the clustering results. <span class="in">`km.out1$betweenss`</span> returns the between-cluster sum of squares. <span class="in">`km.out1$withinss`</span> returns the within-cluster sum of squares for each cluster.  <span class="in">`km.out1$tot.withinss`</span> returns the total within-cluster sum of squares across all K clusters. <span class="in">`km.out1$totss`</span>returns the total sum of squares in this data set.</span>
<span id="cb133-1126"><a href="#cb133-1126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1129"><a href="#cb133-1129" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-1130"><a href="#cb133-1130" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(km.out1<span class="sc">$</span>cluster,iris.labs)</span>
<span id="cb133-1131"><a href="#cb133-1131" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-1132"><a href="#cb133-1132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1133"><a href="#cb133-1133" aria-hidden="true" tabindex="-1"></a>We compare the cluster labels with the original labels by using the function <span class="in">`table()`</span>.</span>
<span id="cb133-1134"><a href="#cb133-1134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1137"><a href="#cb133-1137" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-1138"><a href="#cb133-1138" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb133-1139"><a href="#cb133-1139" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">3</span>)</span>
<span id="cb133-1140"><a href="#cb133-1140" aria-hidden="true" tabindex="-1"></a>km.out2<span class="ot">=</span><span class="fu">kmeans</span>(iris.data,</span>
<span id="cb133-1141"><a href="#cb133-1141" aria-hidden="true" tabindex="-1"></a>               <span class="at">centers=</span><span class="dv">3</span>, <span class="co"># number of k-clusters</span></span>
<span id="cb133-1142"><a href="#cb133-1142" aria-hidden="true" tabindex="-1"></a>               <span class="at">nstart=</span><span class="dv">1</span>) <span class="co"># how many random sets</span></span>
<span id="cb133-1143"><a href="#cb133-1143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1144"><a href="#cb133-1144" aria-hidden="true" tabindex="-1"></a>km.out2<span class="sc">$</span>betweenss</span>
<span id="cb133-1145"><a href="#cb133-1145" aria-hidden="true" tabindex="-1"></a>km.out2<span class="sc">$</span>withinss</span>
<span id="cb133-1146"><a href="#cb133-1146" aria-hidden="true" tabindex="-1"></a>km.out2<span class="sc">$</span>tot.withinss</span>
<span id="cb133-1147"><a href="#cb133-1147" aria-hidden="true" tabindex="-1"></a>km.out2<span class="sc">$</span>totss</span>
<span id="cb133-1148"><a href="#cb133-1148" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(km.out2<span class="sc">$</span>cluster,iris.labs)</span>
<span id="cb133-1149"><a href="#cb133-1149" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-1150"><a href="#cb133-1150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1151"><a href="#cb133-1151" aria-hidden="true" tabindex="-1"></a>Now let’s explore if the initial cluster assignment affects the clustering results. We set a different random seed for Step 1 and then re-run the algorithm. Do we get the same clustering results? Doe the total within cluster sum of squares change? Does the total sum of squares change?</span>
<span id="cb133-1152"><a href="#cb133-1152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1155"><a href="#cb133-1155" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-1156"><a href="#cb133-1156" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb133-1157"><a href="#cb133-1157" aria-hidden="true" tabindex="-1"></a>km.out3 <span class="ot">=</span><span class="fu">kmeans</span>(iris.data, </span>
<span id="cb133-1158"><a href="#cb133-1158" aria-hidden="true" tabindex="-1"></a>                <span class="at">centers=</span><span class="dv">3</span>, <span class="co"># number of k-cluster</span></span>
<span id="cb133-1159"><a href="#cb133-1159" aria-hidden="true" tabindex="-1"></a>                <span class="at">nstart=</span><span class="dv">20</span>) <span class="co"># how many random sets</span></span>
<span id="cb133-1160"><a href="#cb133-1160" aria-hidden="true" tabindex="-1"></a>km.out3<span class="sc">$</span>betweenss</span>
<span id="cb133-1161"><a href="#cb133-1161" aria-hidden="true" tabindex="-1"></a>km.out3<span class="sc">$</span>withinss</span>
<span id="cb133-1162"><a href="#cb133-1162" aria-hidden="true" tabindex="-1"></a>km.out3<span class="sc">$</span>tot.withinss</span>
<span id="cb133-1163"><a href="#cb133-1163" aria-hidden="true" tabindex="-1"></a>km.out3<span class="sc">$</span>totss</span>
<span id="cb133-1164"><a href="#cb133-1164" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(km.out3<span class="sc">$</span>cluster,iris.labs)</span>
<span id="cb133-1165"><a href="#cb133-1165" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-1166"><a href="#cb133-1166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1167"><a href="#cb133-1167" aria-hidden="true" tabindex="-1"></a>We use nstart=1in the previous two models. If a value of nstart greater than one is used, then K-means clustering will be performed using multiple random assignments. It reports only the best results in terms of the total within-cluster</span>
<span id="cb133-1168"><a href="#cb133-1168" aria-hidden="true" tabindex="-1"></a>sum of squares. Now let’s try <span class="in">`nstart=20`</span>. In practice, we usually try a larger value of <span class="in">`nstart`</span>, e.g. 20, 50, to obtain the optimal model. Do we get the same clustering results as the previous two models? Doe the total within-cluster sum of squares change? Does the total sum of squares change?</span>
<span id="cb133-1169"><a href="#cb133-1169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1172"><a href="#cb133-1172" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-1173"><a href="#cb133-1173" aria-hidden="true" tabindex="-1"></a>iris.data2<span class="ot">=</span>iris[,<span class="dv">3</span><span class="sc">:</span><span class="dv">4</span>]</span>
<span id="cb133-1174"><a href="#cb133-1174" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-1175"><a href="#cb133-1175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1176"><a href="#cb133-1176" aria-hidden="true" tabindex="-1"></a>As we learnt in hierarchical clustering, variables Petal.Length and Petal.Width can better differentiate among the three species. Thus, we run models using the only two variables.</span>
<span id="cb133-1177"><a href="#cb133-1177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1180"><a href="#cb133-1180" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-1181"><a href="#cb133-1181" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb133-1182"><a href="#cb133-1182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1183"><a href="#cb133-1183" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb133-1184"><a href="#cb133-1184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1185"><a href="#cb133-1185" aria-hidden="true" tabindex="-1"></a><span class="co"># scale data</span></span>
<span id="cb133-1186"><a href="#cb133-1186" aria-hidden="true" tabindex="-1"></a>sd.data<span class="ot">=</span><span class="fu">scale</span>(iris.data2)</span>
<span id="cb133-1187"><a href="#cb133-1187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1188"><a href="#cb133-1188" aria-hidden="true" tabindex="-1"></a>km.out4<span class="ot">=</span><span class="fu">kmeans</span>(sd.data,</span>
<span id="cb133-1189"><a href="#cb133-1189" aria-hidden="true" tabindex="-1"></a>                <span class="at">centers=</span><span class="dv">3</span>, <span class="co"># number of k-clusters</span></span>
<span id="cb133-1190"><a href="#cb133-1190" aria-hidden="true" tabindex="-1"></a>                <span class="at">nstart =</span><span class="dv">20</span>) <span class="co"># how many random sets</span></span>
<span id="cb133-1191"><a href="#cb133-1191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1192"><a href="#cb133-1192" aria-hidden="true" tabindex="-1"></a>km.out4<span class="sc">$</span>betweenss</span>
<span id="cb133-1193"><a href="#cb133-1193" aria-hidden="true" tabindex="-1"></a>km.out4<span class="sc">$</span>withinss</span>
<span id="cb133-1194"><a href="#cb133-1194" aria-hidden="true" tabindex="-1"></a>km.out4<span class="sc">$</span>tot.withinss</span>
<span id="cb133-1195"><a href="#cb133-1195" aria-hidden="true" tabindex="-1"></a>km.out4<span class="sc">$</span>totss</span>
<span id="cb133-1196"><a href="#cb133-1196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1197"><a href="#cb133-1197" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(km.out4<span class="sc">$</span>cluster,iris.labs)</span>
<span id="cb133-1198"><a href="#cb133-1198" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-1199"><a href="#cb133-1199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1200"><a href="#cb133-1200" aria-hidden="true" tabindex="-1"></a>If we intend to standardize the variables to have mean zero and standard deviation one, we can use the <span class="in">`scale()`</span> function. Again, do we get the same clustering results as the previous two models? Doe the total within-cluster sum of squares change? Does the total sum of squares change? Why?</span>
<span id="cb133-1201"><a href="#cb133-1201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1202"><a href="#cb133-1202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1205"><a href="#cb133-1205" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-1206"><a href="#cb133-1206" aria-hidden="true" tabindex="-1"></a>km.out5<span class="ot">=</span><span class="fu">kmeans</span>(iris.data2,</span>
<span id="cb133-1207"><a href="#cb133-1207" aria-hidden="true" tabindex="-1"></a>               <span class="at">centers=</span><span class="dv">3</span>, <span class="co"># number of k-clusters </span></span>
<span id="cb133-1208"><a href="#cb133-1208" aria-hidden="true" tabindex="-1"></a>               <span class="at">nstart=</span><span class="dv">20</span>) <span class="co"># how many random</span></span>
<span id="cb133-1209"><a href="#cb133-1209" aria-hidden="true" tabindex="-1"></a>km.out5<span class="sc">$</span>betweenss</span>
<span id="cb133-1210"><a href="#cb133-1210" aria-hidden="true" tabindex="-1"></a>km.out5<span class="sc">$</span>withinss</span>
<span id="cb133-1211"><a href="#cb133-1211" aria-hidden="true" tabindex="-1"></a>km.out5<span class="sc">$</span>tot.withinss</span>
<span id="cb133-1212"><a href="#cb133-1212" aria-hidden="true" tabindex="-1"></a>km.out5<span class="sc">$</span>totss</span>
<span id="cb133-1213"><a href="#cb133-1213" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(km.out5<span class="sc">$</span>cluster,iris.labs)</span>
<span id="cb133-1214"><a href="#cb133-1214" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-1215"><a href="#cb133-1215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1216"><a href="#cb133-1216" aria-hidden="true" tabindex="-1"></a>We can compare the results with the model without variable standardization.</span>
<span id="cb133-1217"><a href="#cb133-1217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1220"><a href="#cb133-1220" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb133-1221"><a href="#cb133-1221" aria-hidden="true" tabindex="-1"></a>wss<span class="ot">=</span>km.out5<span class="sc">$</span>totss</span>
<span id="cb133-1222"><a href="#cb133-1222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1223"><a href="#cb133-1223" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span><span class="dv">10</span>)</span>
<span id="cb133-1224"><a href="#cb133-1224" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb133-1225"><a href="#cb133-1225" aria-hidden="true" tabindex="-1"></a>  wss[i] <span class="ot">=</span> <span class="fu">sum</span>(<span class="fu">kmeans</span>(iris.data2,<span class="at">centers=</span>i)<span class="sc">$</span>withinss)</span>
<span id="cb133-1226"><a href="#cb133-1226" aria-hidden="true" tabindex="-1"></a>} </span>
<span id="cb133-1227"><a href="#cb133-1227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1228"><a href="#cb133-1228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1229"><a href="#cb133-1229" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>, wss, </span>
<span id="cb133-1230"><a href="#cb133-1230" aria-hidden="true" tabindex="-1"></a>     <span class="at">type=</span><span class="st">"b"</span>, </span>
<span id="cb133-1231"><a href="#cb133-1231" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">"Number of Clusters"</span>, </span>
<span id="cb133-1232"><a href="#cb133-1232" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">"Within groups sum of squares"</span>, </span>
<span id="cb133-1233"><a href="#cb133-1233" aria-hidden="true" tabindex="-1"></a>     <span class="at">main=</span><span class="st">"find the optimal value of K"</span>)</span>
<span id="cb133-1234"><a href="#cb133-1234" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb133-1235"><a href="#cb133-1235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1236"><a href="#cb133-1236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-1237"><a href="#cb133-1237" aria-hidden="true" tabindex="-1"></a>Once again, do we get the clustering results as the previous two models? Doe the total within-cluster sum of squares change? Does the total sum of squares change?</span>
<span id="cb133-1238"><a href="#cb133-1238" aria-hidden="true" tabindex="-1"></a>We use <span class="in">`K=3`</span> in this case because of our prior knowledge. Now let’s use <span class="in">`km.out5`</span> to check if <span class="in">`K=3`</span> is an optimal choice (you can also check it using other models).  We calculate the total within-cluster sum of squares from <span class="in">`K=1`</span> to <span class="in">`K=10`</span>. Based on the plot, <span class="in">`K=3`</span> is a good choice.</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>